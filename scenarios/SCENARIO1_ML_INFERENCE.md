
# üìä Cen√°rio 1: Machine Learning Inference at the Edge

**Autor:** Pabllo Borges Cardoso  
**Data:** 23 de Outubro de 2025  
**Vers√£o:** 1.0  
**GpuEdgeCloudSim:** v1.0

---

## 1. Vis√£o Geral do Cen√°rio

### 1.1 Contexto
Aplica√ß√µes de infer√™ncia de Machine Learning (ML) em tempo real para detec√ß√£o de objetos e classifica√ß√£o de imagens em dispositivos m√≥veis (smartphones, c√¢meras inteligentes, drones).

### 1.2 Casos de Uso Reais
- **Vigil√¢ncia Inteligente**: Detec√ß√£o de objetos em c√¢meras de seguran√ßa
- **Com√©rcio Inteligente**: Reconhecimento de produtos em lojas automatizadas
- **Assistentes Visuais**: Detec√ß√£o de objetos para deficientes visuais
- **Controle de Tr√°fego**: Detec√ß√£o de ve√≠culos e pedestres

### 1.3 Motiva√ß√£o Cient√≠fica
ML inference no edge reduz lat√™ncia cr√≠tica para aplica√ß√µes em tempo real, mas requer GPUs para throughput adequado. Este cen√°rio investiga o trade-off entre lat√™ncia, energia e custo.

---

## 2. Configura√ß√£o do Cen√°rio

### 2.1 Infraestrutura Edge

```yaml
Edge Servers: 4 datacenters
  - Datacenter 1: 1x NVIDIA T4 (8.1 TFLOPs)
  - Datacenter 2: 1x NVIDIA A100 (19.5 TFLOPs)
  - Datacenter 3: 2x NVIDIA T4 (16.2 TFLOPs total)
  - Datacenter 4: 1x NVIDIA T4 (8.1 TFLOPs)

Total GPU Capacity: 51.9 TFLOPs
```

### 2.2 Dispositivos M√≥veis

```yaml
Mobile Devices: 1000-3000 (incrementos de 500)
Device Types:
  - Smartphones (60%): C√¢meras HD, sensores
  - Smart Cameras (30%): C√¢meras 4K, conex√£o 5G
  - Drones (10%): C√¢meras especializadas, GPS
```

### 2.3 Aplica√ß√µes ML

```yaml
Application Mix:
  - Object Detection (YOLOv5): 50% das tarefas
    - GPU: 250 GFLOPs, 4 GB VRAM
    - Lat√™ncia m√°xima: 500ms
    
  - Image Classification (ResNet-50): 30% das tarefas
    - GPU: 150 GFLOPs, 2 GB VRAM
    - Lat√™ncia m√°xima: 300ms
    
  - Image Segmentation (U-Net): 20% das tarefas
    - GPU: 400 GFLOPs, 6 GB VRAM
    - Lat√™ncia m√°xima: 800ms

Task Arrival: Poisson(Œª=0.1 tasks/second/device)
```

---

## 3. Pol√≠ticas de Orquestra√ß√£o Testadas

### 3.1 NEAREST_GPU
- **Crit√©rio**: Seleciona edge server mais pr√≥ximo com GPU dispon√≠vel
- **Objetivo**: Minimizar lat√™ncia de rede
- **Hip√≥tese**: Proximidade √© fator dominante para QoS

### 3.2 LOAD_BALANCED_GPU
- **Crit√©rio**: Distribui tarefas para GPU com menor utiliza√ß√£o
- **Objetivo**: Maximizar throughput e evitar sobrecarga
- **Hip√≥tese**: Balanceamento previne hotspots

### 3.3 MEMORY_AWARE_GPU
- **Crit√©rio**: Prioriza GPUs com mais mem√≥ria dispon√≠vel
- **Objetivo**: Evitar falhas por falta de VRAM
- **Hip√≥tese**: Mem√≥ria √© gargalo para modelos grandes

### 3.4 ENERGY_EFFICIENT_GPU
- **Crit√©rio**: Minimiza consumo energ√©tico total
- **Objetivo**: Reduzir custo operacional e pegada de carbono
- **Hip√≥tese**: Efici√™ncia energ√©tica √© cr√≠tica para sustentabilidade

### 3.5 HYBRID_GPU (Proposta)
- **Crit√©rio**: Combina√ß√£o ponderada de lat√™ncia (40%), utiliza√ß√£o (30%), mem√≥ria (30%)
- **Objetivo**: Balancear m√∫ltiplos objetivos
- **Hip√≥tese**: Abordagem h√≠brida oferece melhor QoS geral

---

## 4. M√©tricas de Avalia√ß√£o

### 4.1 M√©tricas de Performance

| M√©trica | F√≥rmula | Objetivo |
|---------|---------|----------|
| **Lat√™ncia M√©dia** | $\bar{L} = \frac{1}{N}\sum_{i=1}^{N} (T_{finish}^i - T_{submit}^i)$ | Minimizar |
| **Throughput** | $T = \frac{N_{completed}}{T_{simulation}}$ | Maximizar |
| **Taxa de Sucesso** | $S = \frac{N_{completed}}{N_{submitted}} \times 100\%$ | Maximizar |
| **Lat√™ncia P95** | Lat√™ncia do 95¬∫ percentil | < 1 segundo |
| **Lat√™ncia P99** | Lat√™ncia do 99¬∫ percentil | < 2 segundos |

### 4.2 M√©tricas de Recursos

| M√©trica | F√≥rmula | Objetivo |
|---------|---------|----------|
| **Utiliza√ß√£o GPU M√©dia** | $\bar{U}_{GPU} = \frac{1}{M}\sum_{j=1}^{M} U_j$ | 60-80% (balanceado) |
| **Utiliza√ß√£o GPU M√°xima** | $U_{GPU}^{max} = \max(U_1, ..., U_M)$ | < 95% |
| **Uso de Mem√≥ria GPU** | $M_{used} = \sum_{j=1}^{M} VRAM_j^{used}$ | < 90% da capacidade |
| **Taxa de Rejei√ß√£o** | $R = \frac{N_{rejected}}{N_{submitted}} \times 100\%$ | Minimizar |

### 4.3 M√©tricas de Energia

| M√©trica | F√≥rmula | Objetivo |
|---------|---------|----------|
| **Energia Total** | $E_{total} = \sum_{j=1}^{M} \int_0^T P_j(t) dt$ | Minimizar |
| **Energia por Tarefa** | $E_{task} = \frac{E_{total}}{N_{completed}}$ | Minimizar |
| **Efici√™ncia Energ√©tica** | $\eta = \frac{N_{completed}}{E_{total}}$ | Maximizar |

### 4.4 M√©tricas de Custo

| M√©trica | F√≥rmula | Objetivo |
|---------|---------|----------|
| **Custo Computacional** | $C_{compute} = \sum_{j=1}^{M} (T_j \times r_j)$ | Minimizar |
| **Custo de Rede** | $C_{network} = \sum_{i=1}^{N} (Data_i \times b)$ | Minimizar |
| **Custo Total** | $C_{total} = C_{compute} + C_{network}$ | Minimizar |

---

## 5. Metodologia de Valida√ß√£o

### 5.1 Experimentos

```yaml
Experiment Design:
  Type: Factorial Design 2^3
  Factors:
    - Device Count: [1000, 1500, 2000, 2500, 3000]
    - Orchestration Policy: [NEAREST, LOAD_BALANCED, MEMORY_AWARE, ENERGY, HYBRID]
    - Application Mix: [Light, Medium, Heavy]
  
  Total Configurations: 5 √ó 5 √ó 3 = 75
  
  Replications: 10 (para intervalos de confian√ßa de 95%)
  
  Simulation Time: 600 segundos (10 minutos)
  
  Warm-up Period: 60 segundos
```

### 5.2 An√°lise Estat√≠stica

```python
# An√°lise de Vari√¢ncia (ANOVA)
# H0: N√£o h√° diferen√ßa entre pol√≠ticas de orquestra√ß√£o
# H1: Pelo menos uma pol√≠tica difere significativamente

alpha = 0.05  # N√≠vel de signific√¢ncia

# Teste de Tukey HSD para compara√ß√µes pairwise
# Intervalos de confian√ßa de 95%
```

### 5.3 Valida√ß√£o de Resultados

**Crit√©rios de Aceita√ß√£o:**
- Lat√™ncia m√©dia < 500ms para 90% das tarefas
- Taxa de sucesso > 95%
- Utiliza√ß√£o GPU balanceada (CV < 0.3)
- Energia por tarefa < 100 Joules

---

## 6. Resultados Esperados

### 6.1 Hip√≥teses Cient√≠ficas

**H1:** *NEAREST_GPU oferece menor lat√™ncia para cargas baixas*  
**Justificativa:** Proximidade minimiza atraso de rede quando GPUs n√£o est√£o saturadas.

**H2:** *LOAD_BALANCED_GPU oferece maior throughput para cargas altas*  
**Justificativa:** Distribui√ß√£o uniforme previne sobrecarga de servidores.

**H3:** *HYBRID_GPU oferece melhor QoS geral em todos os cen√°rios*  
**Justificativa:** Abordagem multi-objetivo balanceia trade-offs.

**H4:** *ENERGY_EFFICIENT_GPU reduz custo energ√©tico em > 20%*  
**Justificativa:** Consolida√ß√£o de tarefas reduz GPUs ociosas.

### 6.2 Gr√°ficos de Valida√ß√£o

```yaml
Gr√°ficos Esperados:
  1. Lat√™ncia vs Device Count (por pol√≠tica)
  2. Throughput vs Device Count (por pol√≠tica)
  3. Utiliza√ß√£o GPU (boxplot por datacenter)
  4. Energia Total vs Device Count
  5. Trade-off: Lat√™ncia vs Energia (Pareto frontier)
  6. CDF de Lat√™ncias (compara√ß√£o entre pol√≠ticas)
  7. Heatmap de Utiliza√ß√£o GPU ao longo do tempo
```

---

## 7. Configura√ß√£o para Execu√ß√£o

### 7.1 Arquivo de Configura√ß√£o

```bash
# config/scenario1_ml_inference.properties

simulation_time=600
warm_up_period=60
mobile_device_counter_size=500
min_number_of_mobile_devices=1000
max_number_of_mobile_devices=3000

orchestrator_policies=NEAREST_GPU,LOAD_BALANCED_GPU,MEMORY_AWARE_GPU,ENERGY_EFFICIENT_GPU,HYBRID_GPU

simulation_scenarios=ML_INFERENCE_SCENARIO

edge_devices_file=config/edge_devices.xml
applications_file=config/applications_ml_inference.xml

gpu_enabled=true
gpu_energy_enabled=true
latency_breakdown_tracking=true
```

### 7.2 Comando de Execu√ß√£o

```bash
#!/bin/bash
# run_scenario1.sh

NUM_ITERATIONS=10

for DEVICES in 1000 1500 2000 2500 3000; do
  for POLICY in NEAREST_GPU LOAD_BALANCED_GPU HYBRID_GPU; do
    echo "Running: Devices=$DEVICES, Policy=$POLICY"
    
    java -Xmx4G -cp .:lib/* \
      edu.boun.edgecloudsim.applications.gpusim.GpuSimulationMain \
      $NUM_ITERATIONS $DEVICES $POLICY ML_INFERENCE_SCENARIO
      
    echo "Completed: Devices=$DEVICES, Policy=$POLICY"
  done
done

echo "Scenario 1 completed. Results in sim_results/"
```

---

## 8. Publica√ß√£o Cient√≠fica

### 8.1 Contribui√ß√µes Cient√≠ficas

1. **Benchmark realista** de ML inference no edge com GPUs
2. **Compara√ß√£o emp√≠rica** de pol√≠ticas de orquestra√ß√£o GPU
3. **An√°lise de trade-offs** lat√™ncia-energia-custo
4. **Proposta de pol√≠tica h√≠brida** otimizada

### 8.2 Confer√™ncias Alvo

- **IEEE INFOCOM** (Networking)
- **ACM EdgeSys** (Edge Computing)
- **IEEE/ACM CCGrid** (Cloud and Grid Computing)
- **ACM SoCC** (Symposium on Cloud Computing)

### 8.3 Estrutura do Paper

```markdown
1. Introduction
   - Motiva√ß√£o: ML inference at the edge
   - Problema: Orquestra√ß√£o eficiente de GPUs
   - Contribui√ß√µes: Benchmark + Pol√≠tica h√≠brida

2. Related Work
   - Edge computing simulators
   - GPU resource management
   - ML inference optimization

3. System Model
   - Arquitetura GpuEdgeCloudSim
   - Modelo de GPU
   - Modelo de energia

4. Orchestration Policies
   - NEAREST_GPU
   - LOAD_BALANCED_GPU
   - HYBRID_GPU (proposta)

5. Experimental Setup
   - Cen√°rio ML Inference
   - Configura√ß√µes
   - M√©tricas

6. Results and Analysis
   - Performance comparison
   - Energy analysis
   - Trade-off analysis

7. Conclusion and Future Work
```

---

## 9. Refer√™ncias

[1] Sonmez, C., Ozgovde, A., & Ersoy, C. (2018). EdgeCloudSim: An environment for performance evaluation of edge computing systems. *Transactions on Emerging Telecommunications Technologies*, 29(11), e3493.

[2] Redmon, J., & Farhadi, A. (2018). YOLOv3: An incremental improvement. *arXiv preprint arXiv:1804.02767*.

[3] He, K., Zhang, X., Ren, S., & Sun, J. (2016). Deep residual learning for image recognition. In *CVPR* (pp. 770-778).

[4] Nvidia. (2021). NVIDIA T4 Tensor Core GPU Datasheet.

[5] Nvidia. (2020). NVIDIA A100 Tensor Core GPU Architecture.

---

**Valida√ß√£o Cient√≠fica:** Este cen√°rio foi projetado para ser **reproduz√≠vel**, **realista** e **cientificamente rigoroso**, permitindo publica√ß√£o em confer√™ncias de alto impacto.
