# ğŸ¨ GpuEdgeCloudSim - Fase 2: Design Detalhado das Classes GPU

**Autor:** Pabllo Borges Cardoso  
**Data:** 23 de Outubro de 2025  
**VersÃ£o:** 1.0  
**Projeto:** GpuEdgeCloudSim v1.0 - ExtensÃ£o GPU do EdgeCloudSim

---

## ğŸ“‹ SumÃ¡rio Executivo

Este documento apresenta o **design completo e detalhado** das classes GPU para o **GpuEdgeCloudSim**, incluindo especificaÃ§Ãµes de API, diagramas UML, contratos de interface, diagramas de sequÃªncia, exemplos de uso e estratÃ©gias de teste.

### Contexto da Fase 2

A **Fase 1 (AnÃ¡lise Arquitetural)** identificou 5 pontos crÃ­ticos de extensÃ£o no EdgeCloudSim. Esta Fase 2 detalha o design tÃ©cnico necessÃ¡rio para implementaÃ§Ã£o na **Fase 3**.

### Escopo do Design

Este documento especifica **10 classes GPU principais**:

1. **Gpu** - RepresentaÃ§Ã£o fÃ­sica de uma GPU
2. **GpuProvisioner** - Interface para alocaÃ§Ã£o de GPU
3. **GpuProvisionerSimple** - ImplementaÃ§Ã£o simples de provisionamento
4. **GpuTask** - Tarefa com requisitos GPU
5. **GpuEdgeHost** - Host edge com GPUs fÃ­sicas
6. **GpuEdgeVM** - VM com GPU alocada
7. **GpuCloudletScheduler** - Interface para escalonamento GPU
8. **GpuCloudletSchedulerTimeShared** - ImplementaÃ§Ã£o time-shared
9. **GpuEdgeServerManager** - Gerenciador de infraestrutura GPU
10. **GpuEdgeVmAllocationPolicy_Custom** - PolÃ­tica de alocaÃ§Ã£o GPU-aware

---

## ğŸ“‘ Ãndice

1. [EspecificaÃ§Ãµes Completas de APIs](#1-especificaÃ§Ãµes-completas-de-apis)
2. [Diagramas UML Detalhados](#2-diagramas-uml-detalhados)
3. [Contratos de Interfaces](#3-contratos-de-interfaces)
4. [Diagramas de SequÃªncia](#4-diagramas-de-sequÃªncia)
5. [Exemplos de Uso](#5-exemplos-de-uso)
6. [EstratÃ©gias de Teste](#6-estratÃ©gias-de-teste)
7. [DecisÃµes de Design](#7-decisÃµes-de-design)
8. [Anexos](#8-anexos)

---

## 1. EspecificaÃ§Ãµes Completas de APIs

### 1.1 Classe: Gpu

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** Representa uma GPU fÃ­sica em um EdgeHost, modelando suas caracterÃ­sticas de hardware e estado de utilizaÃ§Ã£o.

**Relacionamentos:**
- Agregada por: `GpuEdgeHost`
- Alocada para: `GpuEdgeVM`
- Gerenciada por: `GpuProvisioner`

#### Atributos

```java
/**
 * Identificador Ãºnico da GPU dentro do host.
 * @visibility private
 * @type int
 */
private int id;

/**
 * Tipo/modelo da GPU (ex: "NVIDIA_T4", "NVIDIA_A100").
 * @visibility private
 * @type String
 */
private String gpuType;

/**
 * NÃºmero de CUDA cores disponÃ­veis.
 * @visibility private
 * @type int
 */
private int cudaCores;

/**
 * Capacidade computacional em GFLOPS (Giga Floating Point Operations Per Second).
 * @visibility private
 * @type double
 */
private double gflops;

/**
 * MemÃ³ria total da GPU em MB.
 * @visibility private
 * @type long
 */
private long gpuMemory;

/**
 * Largura de banda da memÃ³ria GPU em GB/s.
 * @visibility private
 * @type double
 */
private double memoryBandwidth;

/**
 * UtilizaÃ§Ã£o atual da GPU em percentual (0-100%).
 * @visibility private
 * @type double
 */
private double utilization;

/**
 * MemÃ³ria GPU atualmente ocupada em MB.
 * @visibility private
 * @type long
 */
private long usedMemory;

/**
 * VM atualmente alocada nesta GPU (null se disponÃ­vel).
 * @visibility private
 * @type GpuEdgeVM
 */
private GpuEdgeVM allocatedVm;

/**
 * Host que contÃ©m esta GPU.
 * @visibility private
 * @type GpuEdgeHost
 */
private GpuEdgeHost host;
```

#### Construtores

```java
/**
 * Construtor completo para criar uma GPU com todas as especificaÃ§Ãµes.
 * 
 * @param id Identificador Ãºnico da GPU
 * @param gpuType Tipo/modelo da GPU
 * @param cudaCores NÃºmero de CUDA cores
 * @param gflops Capacidade em GFLOPS
 * @param gpuMemory MemÃ³ria total em MB
 * @param memoryBandwidth Largura de banda em GB/s
 */
public Gpu(int id, String gpuType, int cudaCores, double gflops, 
           long gpuMemory, double memoryBandwidth)

/**
 * Construtor simplificado para criar uma GPU com especificaÃ§Ãµes bÃ¡sicas.
 * 
 * @param id Identificador Ãºnico da GPU
 * @param cudaCores NÃºmero de CUDA cores
 * @param gflops Capacidade em GFLOPS
 * @param gpuMemory MemÃ³ria total em MB
 */
public Gpu(int id, int cudaCores, double gflops, long gpuMemory)
```

#### MÃ©todos

##### Getters BÃ¡sicos

```java
/**
 * Retorna o identificador Ãºnico da GPU.
 * @return ID da GPU
 */
public int getId()

/**
 * Retorna o tipo/modelo da GPU.
 * @return Tipo da GPU (ex: "NVIDIA_T4")
 */
public String getGpuType()

/**
 * Retorna o nÃºmero de CUDA cores.
 * @return NÃºmero de CUDA cores
 */
public int getCudaCores()

/**
 * Retorna a capacidade computacional em GFLOPS.
 * @return Capacidade em GFLOPS
 */
public double getGflops()

/**
 * Retorna a memÃ³ria total da GPU em MB.
 * @return MemÃ³ria total em MB
 */
public long getGpuMemory()

/**
 * Retorna a largura de banda da memÃ³ria em GB/s.
 * @return Largura de banda em GB/s
 */
public double getMemoryBandwidth()

/**
 * Retorna o host que contÃ©m esta GPU.
 * @return Host da GPU
 */
public GpuEdgeHost getHost()
```

##### Getters de Estado

```java
/**
 * Retorna a utilizaÃ§Ã£o atual da GPU em percentual.
 * @return UtilizaÃ§Ã£o (0-100%)
 */
public double getUtilization()

/**
 * Retorna a memÃ³ria GPU atualmente ocupada em MB.
 * @return MemÃ³ria ocupada em MB
 */
public long getUsedMemory()

/**
 * Retorna a memÃ³ria GPU disponÃ­vel em MB.
 * @return MemÃ³ria disponÃ­vel em MB
 */
public long getAvailableMemory()

/**
 * Retorna a VM atualmente alocada nesta GPU.
 * @return VM alocada ou null se disponÃ­vel
 */
public GpuEdgeVM getAllocatedVm()

/**
 * Verifica se a GPU estÃ¡ disponÃ­vel (nÃ£o alocada).
 * @return true se disponÃ­vel, false caso contrÃ¡rio
 */
public boolean isAvailable()
```

##### Setters

```java
/**
 * Define o host que contÃ©m esta GPU.
 * @param host Host da GPU
 */
public void setHost(GpuEdgeHost host)

/**
 * Define a utilizaÃ§Ã£o atual da GPU.
 * @param utilization UtilizaÃ§Ã£o em percentual (0-100%)
 */
public void setUtilization(double utilization)

/**
 * Define a memÃ³ria GPU atualmente ocupada.
 * @param usedMemory MemÃ³ria ocupada em MB
 */
public void setUsedMemory(long usedMemory)

/**
 * Define a VM alocada nesta GPU.
 * @param vm VM a ser alocada (null para desalocar)
 */
public void setAllocatedVm(GpuEdgeVM vm)
```

##### MÃ©todos de Gerenciamento

```java
/**
 * Aloca memÃ³ria GPU para uma tarefa.
 * 
 * @param memorySize Quantidade de memÃ³ria a alocar em MB
 * @return true se a alocaÃ§Ã£o foi bem-sucedida, false caso contrÃ¡rio
 */
public boolean allocateMemory(long memorySize)

/**
 * Libera memÃ³ria GPU previamente alocada.
 * 
 * @param memorySize Quantidade de memÃ³ria a liberar em MB
 * @return true se a liberaÃ§Ã£o foi bem-sucedida, false caso contrÃ¡rio
 */
public boolean deallocateMemory(long memorySize)

/**
 * Calcula o tempo de execuÃ§Ã£o de uma tarefa nesta GPU.
 * 
 * @param gpuLength Tamanho da tarefa em GFLOPs
 * @return Tempo de execuÃ§Ã£o em segundos
 */
public double calculateExecutionTime(long gpuLength)

/**
 * Calcula o tempo de transferÃªncia de dados para a GPU.
 * 
 * @param dataSize Tamanho dos dados em MB
 * @return Tempo de transferÃªncia em segundos
 */
public double calculateDataTransferTime(long dataSize)

/**
 * Reseta a GPU para o estado inicial (disponÃ­vel).
 */
public void reset()
```

##### MÃ©todos de String

```java
/**
 * Retorna representaÃ§Ã£o em string da GPU.
 * @return String com informaÃ§Ãµes bÃ¡sicas da GPU
 */
@Override
public String toString()
```

---

### 1.2 Interface: GpuProvisioner

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** Define o contrato para provisionamento de GPUs para VMs.

**ImplementaÃ§Ãµes:** `GpuProvisionerSimple`

#### MÃ©todos

```java
/**
 * Aloca uma GPU especÃ­fica para uma VM.
 * 
 * @param vm VM que receberÃ¡ a GPU
 * @param gpu GPU a ser alocada
 * @return true se a alocaÃ§Ã£o foi bem-sucedida, false caso contrÃ¡rio
 */
boolean allocateGpuForVm(GpuEdgeVM vm, Gpu gpu);

/**
 * Desaloca a GPU de uma VM, tornando-a disponÃ­vel.
 * 
 * @param vm VM da qual a GPU serÃ¡ desalocada
 */
void deallocateGpuForVm(GpuEdgeVM vm);

/**
 * Verifica se hÃ¡ GPUs disponÃ­veis no pool.
 * 
 * @return true se hÃ¡ pelo menos uma GPU disponÃ­vel, false caso contrÃ¡rio
 */
boolean hasAvailableGpu();

/**
 * Retorna uma GPU disponÃ­vel do pool.
 * EstratÃ©gia de seleÃ§Ã£o depende da implementaÃ§Ã£o.
 * 
 * @return GPU disponÃ­vel ou null se nÃ£o houver
 */
Gpu getAvailableGpu();

/**
 * Retorna uma GPU disponÃ­vel com memÃ³ria suficiente.
 * 
 * @param requiredMemory MemÃ³ria mÃ­nima necessÃ¡ria em MB
 * @return GPU disponÃ­vel com memÃ³ria suficiente ou null
 */
Gpu getAvailableGpuWithMemory(long requiredMemory);

/**
 * Retorna a lista completa de GPUs gerenciadas.
 * 
 * @return Lista de todas as GPUs
 */
List<Gpu> getGpuList();

/**
 * Retorna a lista de GPUs disponÃ­veis (nÃ£o alocadas).
 * 
 * @return Lista de GPUs disponÃ­veis
 */
List<Gpu> getAvailableGpuList();

/**
 * Retorna a lista de GPUs alocadas.
 * 
 * @return Lista de GPUs alocadas
 */
List<Gpu> getAllocatedGpuList();
```

---

### 1.3 Classe: GpuProvisionerSimple

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** ImplementaÃ§Ã£o simples de provisionamento de GPU com alocaÃ§Ã£o exclusiva (1 GPU : 1 VM).

**Relacionamentos:**
- Implementa: `GpuProvisioner`
- Usado por: `GpuEdgeHost`

#### Atributos

```java
/**
 * Lista de GPUs gerenciadas por este provisioner.
 * @visibility private
 * @type List<Gpu>
 */
private List<Gpu> gpuList;

/**
 * Mapa para rastrear alocaÃ§Ãµes VM -> GPU.
 * @visibility private
 * @type Map<Integer, Gpu>
 */
private Map<Integer, Gpu> vmGpuMap;
```

#### Construtores

```java
/**
 * Construtor que inicializa o provisioner com uma lista de GPUs.
 * 
 * @param gpuList Lista de GPUs a serem gerenciadas
 */
public GpuProvisionerSimple(List<Gpu> gpuList)
```

#### MÃ©todos

```java
/**
 * Aloca uma GPU especÃ­fica para uma VM (modo exclusivo).
 * Verifica disponibilidade antes de alocar.
 * 
 * @param vm VM que receberÃ¡ a GPU
 * @param gpu GPU a ser alocada
 * @return true se a alocaÃ§Ã£o foi bem-sucedida, false caso contrÃ¡rio
 */
@Override
public boolean allocateGpuForVm(GpuEdgeVM vm, Gpu gpu)

/**
 * Desaloca a GPU de uma VM.
 * Reseta o estado da GPU e remove do mapa de alocaÃ§Ãµes.
 * 
 * @param vm VM da qual a GPU serÃ¡ desalocada
 */
@Override
public void deallocateGpuForVm(GpuEdgeVM vm)

/**
 * Verifica se hÃ¡ GPUs disponÃ­veis.
 * 
 * @return true se hÃ¡ pelo menos uma GPU disponÃ­vel
 */
@Override
public boolean hasAvailableGpu()

/**
 * Retorna a primeira GPU disponÃ­vel encontrada.
 * 
 * @return GPU disponÃ­vel ou null
 */
@Override
public Gpu getAvailableGpu()

/**
 * Retorna uma GPU disponÃ­vel com memÃ³ria suficiente.
 * 
 * @param requiredMemory MemÃ³ria mÃ­nima necessÃ¡ria em MB
 * @return GPU disponÃ­vel com memÃ³ria suficiente ou null
 */
@Override
public Gpu getAvailableGpuWithMemory(long requiredMemory)

/**
 * Retorna a lista completa de GPUs.
 * 
 * @return Lista imutÃ¡vel de GPUs
 */
@Override
public List<Gpu> getGpuList()

/**
 * Retorna a lista de GPUs disponÃ­veis.
 * 
 * @return Lista de GPUs nÃ£o alocadas
 */
@Override
public List<Gpu> getAvailableGpuList()

/**
 * Retorna a lista de GPUs alocadas.
 * 
 * @return Lista de GPUs alocadas
 */
@Override
public List<Gpu> getAllocatedGpuList()

/**
 * Retorna a GPU alocada para uma VM especÃ­fica.
 * 
 * @param vmId ID da VM
 * @return GPU alocada para a VM ou null
 */
public Gpu getGpuForVm(int vmId)

/**
 * Calcula a utilizaÃ§Ã£o mÃ©dia de todas as GPUs.
 * 
 * @return UtilizaÃ§Ã£o mÃ©dia em percentual (0-100%)
 */
public double getAverageUtilization()
```

---

### 1.4 Classe: GpuTask

**Pacote:** `edu.boun.edgecloudsim.edge_client`

**PropÃ³sito:** Estende Task para incluir requisitos e mÃ©tricas de processamento GPU.

**Relacionamentos:**
- Estende: `Task`
- Processada por: `GpuEdgeVM`
- Escalonada por: `GpuCloudletScheduler`

#### Atributos

```java
/**
 * Tamanho da carga de trabalho GPU em GFLOPs.
 * @visibility private
 * @type long
 */
private long gpuLength;

/**
 * Tamanho dos dados de entrada para a GPU em MB.
 * @visibility private
 * @type long
 */
private long gpuInputData;

/**
 * Tamanho dos dados de saÃ­da da GPU em MB.
 * @visibility private
 * @type long
 */
private long gpuOutputData;

/**
 * MemÃ³ria GPU necessÃ¡ria em MB.
 * @visibility private
 * @type long
 */
private long requiredGpuMemory;

/**
 * UtilizaÃ§Ã£o GPU esperada em percentual (0-100%).
 * @visibility private
 * @type double
 */
private double expectedGpuUtilization;

/**
 * ID da GPU onde esta tarefa foi executada.
 * @visibility private
 * @type int
 */
private int executedGpuId;

/**
 * Tempo de transferÃªncia CPU â†’ GPU em segundos.
 * @visibility private
 * @type double
 */
private double gpuDataTransferTime;

/**
 * Tempo de execuÃ§Ã£o na GPU em segundos.
 * @visibility private
 * @type double
 */
private double gpuExecutionTime;

/**
 * Tempo de transferÃªncia GPU â†’ CPU em segundos.
 * @visibility private
 * @type double
 */
private double gpuDataBackTime;

/**
 * UtilizaÃ§Ã£o GPU real durante a execuÃ§Ã£o (0-100%).
 * @visibility private
 * @type double
 */
private double actualGpuUtilization;

/**
 * Timestamp do inÃ­cio da transferÃªncia CPU â†’ GPU.
 * @visibility private
 * @type double
 */
private double gpuStartTime;

/**
 * Timestamp do fim da execuÃ§Ã£o GPU completa.
 * @visibility private
 * @type double
 */
private double gpuFinishTime;
```

#### Construtores

```java
/**
 * Construtor completo para GpuTask com requisitos CPU e GPU.
 * 
 * @param mobileDeviceId ID do dispositivo que gerou a tarefa
 * @param cloudletId ID Ãºnico da tarefa
 * @param cloudletLength Tamanho do processamento CPU em MI
 * @param pesNumber NÃºmero de PEs (CPU cores) necessÃ¡rios
 * @param cloudletFileSize Tamanho do arquivo de entrada em bytes
 * @param cloudletOutputSize Tamanho do arquivo de saÃ­da em bytes
 * @param utilizationModelCpu Modelo de utilizaÃ§Ã£o de CPU
 * @param utilizationModelRam Modelo de utilizaÃ§Ã£o de RAM
 * @param utilizationModelBw Modelo de utilizaÃ§Ã£o de largura de banda
 * @param gpuLength Tamanho da carga GPU em GFLOPs
 * @param gpuInputData Dados de entrada para GPU em MB
 * @param gpuOutputData Dados de saÃ­da da GPU em MB
 * @param requiredGpuMemory MemÃ³ria GPU necessÃ¡ria em MB
 */
public GpuTask(int mobileDeviceId, int cloudletId, long cloudletLength, 
               int pesNumber, long cloudletFileSize, long cloudletOutputSize,
               UtilizationModel utilizationModelCpu,
               UtilizationModel utilizationModelRam,
               UtilizationModel utilizationModelBw,
               long gpuLength, long gpuInputData, long gpuOutputData,
               long requiredGpuMemory)

/**
 * Construtor simplificado para GpuTask (herda Task).
 * 
 * @param cloudletId ID Ãºnico da tarefa
 * @param taskId ID do tipo de tarefa
 * @param cloudletLength Tamanho do processamento CPU em MI
 * @param pesNumber NÃºmero de PEs necessÃ¡rios
 * @param cloudletFileSize Tamanho do arquivo de entrada
 * @param cloudletOutputSize Tamanho do arquivo de saÃ­da
 * @param gpuLength Tamanho da carga GPU em GFLOPs
 * @param gpuInputData Dados de entrada para GPU em MB
 * @param gpuOutputData Dados de saÃ­da da GPU em MB
 * @param requiredGpuMemory MemÃ³ria GPU necessÃ¡ria em MB
 */
public GpuTask(int cloudletId, int taskId, long cloudletLength, 
               long pesNumber, long cloudletFileSize, long cloudletOutputSize,
               long gpuLength, long gpuInputData, long gpuOutputData,
               long requiredGpuMemory)
```

#### MÃ©todos

##### Getters de Requisitos GPU

```java
/**
 * Retorna o tamanho da carga de trabalho GPU.
 * @return Tamanho em GFLOPs
 */
public long getGpuLength()

/**
 * Retorna o tamanho dos dados de entrada para GPU.
 * @return Tamanho em MB
 */
public long getGpuInputData()

/**
 * Retorna o tamanho dos dados de saÃ­da da GPU.
 * @return Tamanho em MB
 */
public long getGpuOutputData()

/**
 * Retorna a memÃ³ria GPU necessÃ¡ria.
 * @return MemÃ³ria em MB
 */
public long getRequiredGpuMemory()

/**
 * Retorna a utilizaÃ§Ã£o GPU esperada.
 * @return UtilizaÃ§Ã£o esperada em percentual (0-100%)
 */
public double getExpectedGpuUtilization()
```

##### Getters de MÃ©tricas GPU

```java
/**
 * Retorna o ID da GPU onde a tarefa foi executada.
 * @return ID da GPU ou -1 se nÃ£o executada
 */
public int getExecutedGpuId()

/**
 * Retorna o tempo de transferÃªncia CPU â†’ GPU.
 * @return Tempo em segundos
 */
public double getGpuDataTransferTime()

/**
 * Retorna o tempo de execuÃ§Ã£o na GPU.
 * @return Tempo em segundos
 */
public double getGpuExecutionTime()

/**
 * Retorna o tempo de transferÃªncia GPU â†’ CPU.
 * @return Tempo em segundos
 */
public double getGpuDataBackTime()

/**
 * Retorna a utilizaÃ§Ã£o GPU real durante execuÃ§Ã£o.
 * @return UtilizaÃ§Ã£o em percentual (0-100%)
 */
public double getActualGpuUtilization()

/**
 * Retorna o timestamp de inÃ­cio da execuÃ§Ã£o GPU.
 * @return Timestamp em segundos de simulaÃ§Ã£o
 */
public double getGpuStartTime()

/**
 * Retorna o timestamp de fim da execuÃ§Ã£o GPU.
 * @return Timestamp em segundos de simulaÃ§Ã£o
 */
public double getGpuFinishTime()
```

##### Setters de MÃ©tricas GPU

```java
/**
 * Define o ID da GPU onde a tarefa foi executada.
 * @param gpuId ID da GPU
 */
public void setExecutedGpuId(int gpuId)

/**
 * Define o tempo de transferÃªncia CPU â†’ GPU.
 * @param time Tempo em segundos
 */
public void setGpuDataTransferTime(double time)

/**
 * Define o tempo de execuÃ§Ã£o na GPU.
 * @param time Tempo em segundos
 */
public void setGpuExecutionTime(double time)

/**
 * Define o tempo de transferÃªncia GPU â†’ CPU.
 * @param time Tempo em segundos
 */
public void setGpuDataBackTime(double time)

/**
 * Define a utilizaÃ§Ã£o GPU real durante execuÃ§Ã£o.
 * @param utilization UtilizaÃ§Ã£o em percentual (0-100%)
 */
public void setActualGpuUtilization(double utilization)

/**
 * Define o timestamp de inÃ­cio da execuÃ§Ã£o GPU.
 * @param time Timestamp em segundos de simulaÃ§Ã£o
 */
public void setGpuStartTime(double time)

/**
 * Define o timestamp de fim da execuÃ§Ã£o GPU.
 * @param time Timestamp em segundos de simulaÃ§Ã£o
 */
public void setGpuFinishTime(double time)

/**
 * Define a utilizaÃ§Ã£o GPU esperada.
 * @param utilization UtilizaÃ§Ã£o esperada em percentual (0-100%)
 */
public void setExpectedGpuUtilization(double utilization)
```

##### MÃ©todos de CÃ¡lculo

```java
/**
 * Calcula o tempo total de processamento GPU.
 * Inclui transferÃªncias de dados e execuÃ§Ã£o.
 * 
 * @return Tempo total em segundos
 */
public double getTotalGpuTime()

/**
 * Verifica se esta tarefa requer processamento GPU.
 * 
 * @return true se gpuLength > 0, false caso contrÃ¡rio
 */
public boolean requiresGpu()

/**
 * Calcula a proporÃ§Ã£o de processamento GPU em relaÃ§Ã£o ao total.
 * 
 * @return RazÃ£o GPU/(CPU+GPU) entre 0 e 1
 */
public double getGpuIntensity()

/**
 * Verifica se a tarefa tem memÃ³ria GPU suficiente alocada.
 * 
 * @param availableMemory MemÃ³ria disponÃ­vel em MB
 * @return true se a memÃ³ria Ã© suficiente, false caso contrÃ¡rio
 */
public boolean hasEnoughGpuMemory(long availableMemory)
```

---

### 1.5 Classe: GpuEdgeHost

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** Estende EdgeHost para incluir gerenciamento de GPUs fÃ­sicas.

**Relacionamentos:**
- Estende: `EdgeHost`
- ContÃ©m: `List<Gpu>`
- Usa: `GpuProvisioner`
- Gerencia: `GpuEdgeVM`

#### Atributos

```java
/**
 * Lista de GPUs fÃ­sicas disponÃ­veis neste host.
 * @visibility private
 * @type List<Gpu>
 */
private List<Gpu> gpuList;

/**
 * Provisionador responsÃ¡vel por alocar GPUs para VMs.
 * @visibility private
 * @type GpuProvisioner
 */
private GpuProvisioner gpuProvisioner;
```

#### Construtores

```java
/**
 * Construtor completo para GpuEdgeHost com recursos CPU e GPU.
 * 
 * @param id Identificador Ãºnico do host
 * @param ramProvisioner Provisionador de memÃ³ria RAM
 * @param bwProvisioner Provisionador de largura de banda
 * @param storage Capacidade de armazenamento em MB
 * @param peList Lista de elementos de processamento (CPU cores)
 * @param vmScheduler Escalonador de VMs
 * @param gpuList Lista de GPUs disponÃ­veis
 * @param gpuProvisioner Provisionador de GPUs
 */
public GpuEdgeHost(int id, RamProvisioner ramProvisioner,
                   BwProvisioner bwProvisioner, long storage,
                   List<? extends Pe> peList, VmScheduler vmScheduler,
                   List<Gpu> gpuList, GpuProvisioner gpuProvisioner)
```

#### MÃ©todos

##### Getters

```java
/**
 * Retorna a lista de GPUs deste host.
 * @return Lista de GPUs
 */
public List<Gpu> getGpuList()

/**
 * Retorna o provisionador de GPU.
 * @return Provisionador de GPU
 */
public GpuProvisioner getGpuProvisioner()

/**
 * Retorna o nÃºmero total de GPUs neste host.
 * @return NÃºmero de GPUs
 */
public int getNumberOfGpus()

/**
 * Retorna uma GPU especÃ­fica pelo ID.
 * 
 * @param gpuId ID da GPU
 * @return GPU correspondente ou null se nÃ£o encontrada
 */
public Gpu getGpu(int gpuId)
```

##### MÃ©todos de AlocaÃ§Ã£o GPU

```java
/**
 * Aloca uma GPU especÃ­fica para uma VM.
 * Delega ao GpuProvisioner para realizar a alocaÃ§Ã£o.
 * 
 * @param vm VM que receberÃ¡ a GPU
 * @param gpu GPU a ser alocada
 * @return true se a alocaÃ§Ã£o foi bem-sucedida, false caso contrÃ¡rio
 */
public boolean allocateGpuForVm(GpuEdgeVM vm, Gpu gpu)

/**
 * Desaloca a GPU de uma VM.
 * Libera a GPU para outras VMs.
 * 
 * @param vm VM da qual a GPU serÃ¡ desalocada
 */
public void deallocateGpuForVm(GpuEdgeVM vm)

/**
 * Verifica se hÃ¡ GPUs disponÃ­veis neste host.
 * 
 * @return true se hÃ¡ pelo menos uma GPU disponÃ­vel
 */
public boolean hasAvailableGpu()

/**
 * Retorna uma GPU disponÃ­vel do pool.
 * 
 * @return GPU disponÃ­vel ou null se nenhuma disponÃ­vel
 */
public Gpu getAvailableGpu()

/**
 * Retorna uma GPU disponÃ­vel com memÃ³ria suficiente.
 * 
 * @param requiredMemory MemÃ³ria mÃ­nima necessÃ¡ria em MB
 * @return GPU disponÃ­vel com memÃ³ria suficiente ou null
 */
public Gpu getAvailableGpuWithMemory(long requiredMemory)
```

##### MÃ©todos de MÃ©tricas

```java
/**
 * Calcula a utilizaÃ§Ã£o mÃ©dia de CPU e GPU.
 * Combina utilizaÃ§Ã£o de CPU (herdada) e GPU.
 * 
 * @return UtilizaÃ§Ã£o mÃ©dia em percentual (0-100%)
 */
public double getAvgUtilization()

/**
 * Calcula a utilizaÃ§Ã£o mÃ©dia das GPUs.
 * 
 * @return UtilizaÃ§Ã£o mÃ©dia das GPUs em percentual (0-100%)
 */
public double getAvgGpuUtilization()

/**
 * Retorna a memÃ³ria GPU total disponÃ­vel neste host.
 * 
 * @return MemÃ³ria GPU total em MB
 */
public long getTotalGpuMemory()

/**
 * Retorna a memÃ³ria GPU disponÃ­vel (nÃ£o alocada) neste host.
 * 
 * @return MemÃ³ria GPU disponÃ­vel em MB
 */
public long getAvailableGpuMemory()

/**
 * Retorna a capacidade computacional total de GPU em GFLOPS.
 * 
 * @return Capacidade total em GFLOPS
 */
public double getTotalGpuGflops()
```

##### MÃ©todos de CriaÃ§Ã£o de VM (Override)

```java
/**
 * Cria uma VM neste host (estende comportamento do Host).
 * Se a VM requer GPU, tenta alocar uma antes de criar a VM.
 * 
 * @param vm VM a ser criada
 * @return true se a VM foi criada com sucesso, false caso contrÃ¡rio
 */
@Override
public boolean vmCreate(Vm vm)

/**
 * DestrÃ³i uma VM neste host (estende comportamento do Host).
 * Libera a GPU alocada se a VM tiver uma.
 * 
 * @param vm VM a ser destruÃ­da
 */
@Override
public void vmDestroy(Vm vm)
```

---

### 1.6 Classe: GpuEdgeVM

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** Estende EdgeVM para incluir GPU alocada e escalonamento GPU.

**Relacionamentos:**
- Estende: `EdgeVM`
- Possui: `Gpu` (alocada)
- Usa: `GpuCloudletScheduler`
- Executa: `GpuTask`

#### Atributos

```java
/**
 * GPU alocada para esta VM (null se nÃ£o tiver GPU).
 * @visibility private
 * @type Gpu
 */
private Gpu allocatedGpu;

/**
 * Escalonador de tarefas GPU para esta VM.
 * @visibility private
 * @type GpuCloudletScheduler
 */
private GpuCloudletScheduler gpuCloudletScheduler;

/**
 * Indica se esta VM requer GPU.
 * @visibility private
 * @type boolean
 */
private boolean requiresGpu;

/**
 * Modo de alocaÃ§Ã£o GPU (EXCLUSIVE ou SHARED).
 * @visibility private
 * @type GpuAllocationMode
 */
private GpuAllocationMode gpuAllocationMode;
```

#### EnumeraÃ§Ã£o Interna

```java
/**
 * Modos de alocaÃ§Ã£o de GPU para VMs.
 */
public enum GpuAllocationMode {
    /**
     * Modo exclusivo: 1 GPU : 1 VM
     */
    EXCLUSIVE,
    
    /**
     * Modo compartilhado: 1 GPU : N VMs (futuro)
     */
    SHARED
}
```

#### Construtores

```java
/**
 * Construtor completo para GpuEdgeVM com suporte a GPU.
 * 
 * @param id Identificador Ãºnico da VM
 * @param userId ID do usuÃ¡rio/broker
 * @param mips Capacidade de processamento em MIPS
 * @param numberOfPes NÃºmero de cores de CPU
 * @param ram MemÃ³ria RAM em MB
 * @param bw Largura de banda em Mbps
 * @param size Armazenamento em MB
 * @param vmm Monitor de mÃ¡quina virtual
 * @param cloudletScheduler Escalonador de tarefas CPU
 * @param gpuCloudletScheduler Escalonador de tarefas GPU
 * @param requiresGpu Indica se esta VM requer GPU
 */
public GpuEdgeVM(int id, int userId, double mips, int numberOfPes,
                 int ram, long bw, long size, String vmm,
                 CloudletScheduler cloudletScheduler,
                 GpuCloudletScheduler gpuCloudletScheduler,
                 boolean requiresGpu)

/**
 * Construtor alternativo sem escalonador GPU (para VMs sem GPU).
 * 
 * @param id Identificador Ãºnico da VM
 * @param userId ID do usuÃ¡rio/broker
 * @param mips Capacidade de processamento em MIPS
 * @param numberOfPes NÃºmero de cores de CPU
 * @param ram MemÃ³ria RAM em MB
 * @param bw Largura de banda em Mbps
 * @param size Armazenamento em MB
 * @param vmm Monitor de mÃ¡quina virtual
 * @param cloudletScheduler Escalonador de tarefas CPU
 */
public GpuEdgeVM(int id, int userId, double mips, int numberOfPes,
                 int ram, long bw, long size, String vmm,
                 CloudletScheduler cloudletScheduler)
```

#### MÃ©todos

##### Getters e Setters GPU

```java
/**
 * Define a GPU alocada para esta VM.
 * @param gpu GPU a ser alocada
 */
public void setGpu(Gpu gpu)

/**
 * Retorna a GPU alocada para esta VM.
 * @return GPU alocada ou null
 */
public Gpu getGpu()

/**
 * Verifica se esta VM possui GPU alocada.
 * @return true se tem GPU alocada, false caso contrÃ¡rio
 */
public boolean hasGpu()

/**
 * Verifica se esta VM requer GPU.
 * @return true se requer GPU, false caso contrÃ¡rio
 */
public boolean requiresGpu()

/**
 * Define se esta VM requer GPU.
 * @param requiresGpu true se requer, false caso contrÃ¡rio
 */
public void setRequiresGpu(boolean requiresGpu)

/**
 * Retorna o escalonador de tarefas GPU.
 * @return Escalonador GPU ou null
 */
public GpuCloudletScheduler getGpuCloudletScheduler()

/**
 * Define o escalonador de tarefas GPU.
 * @param scheduler Escalonador GPU
 */
public void setGpuCloudletScheduler(GpuCloudletScheduler scheduler)

/**
 * Retorna o modo de alocaÃ§Ã£o GPU.
 * @return Modo de alocaÃ§Ã£o (EXCLUSIVE ou SHARED)
 */
public GpuAllocationMode getGpuAllocationMode()

/**
 * Define o modo de alocaÃ§Ã£o GPU.
 * @param mode Modo de alocaÃ§Ã£o
 */
public void setGpuAllocationMode(GpuAllocationMode mode)
```

##### MÃ©todos de ExecuÃ§Ã£o GPU

```java
/**
 * Submete uma tarefa GPU para execuÃ§Ã£o nesta VM.
 * Delega ao GpuCloudletScheduler.
 * 
 * @param gpuTask Tarefa GPU a ser executada
 * @return true se a tarefa foi aceita, false caso contrÃ¡rio
 */
public boolean submitGpuTask(GpuTask gpuTask)

/**
 * Remove uma tarefa GPU da fila de execuÃ§Ã£o.
 * 
 * @param gpuTask Tarefa GPU a ser removida
 * @return true se a tarefa foi removida, false caso contrÃ¡rio
 */
public boolean removeGpuTask(GpuTask gpuTask)

/**
 * Retorna a lista de tarefas GPU em execuÃ§Ã£o.
 * 
 * @return Lista de GpuTasks em execuÃ§Ã£o
 */
public List<GpuTask> getRunningGpuTasks()

/**
 * Retorna o nÃºmero de tarefas GPU em execuÃ§Ã£o.
 * 
 * @return NÃºmero de tarefas GPU ativas
 */
public int getNumberOfRunningGpuTasks()
```

##### MÃ©todos de MÃ©tricas GPU

```java
/**
 * Calcula a utilizaÃ§Ã£o atual da GPU.
 * Retorna 0 se nÃ£o tiver GPU alocada.
 * 
 * @return UtilizaÃ§Ã£o GPU em percentual (0-100%)
 */
public double getGpuUtilization()

/**
 * Calcula a utilizaÃ§Ã£o combinada de CPU e GPU.
 * 
 * @return UtilizaÃ§Ã£o mÃ©dia (CPU + GPU) / 2
 */
public double getCombinedUtilization()

/**
 * Retorna a memÃ³ria GPU disponÃ­vel nesta VM.
 * 
 * @return MemÃ³ria GPU disponÃ­vel em MB ou 0 se sem GPU
 */
public long getAvailableGpuMemory()

/**
 * Retorna a capacidade computacional GPU desta VM.
 * 
 * @return Capacidade em GFLOPS ou 0 se sem GPU
 */
public double getGpuGflops()
```

##### MÃ©todos de ReconfiguraÃ§Ã£o

```java
/**
 * Reconfigura a capacidade da GPU (se suportado).
 * ImplementaÃ§Ã£o futura para time-slicing dinÃ¢mico.
 * 
 * @param newGflops Nova capacidade em GFLOPS
 */
public void reconfigureGpu(double newGflops)
```

---

### 1.7 Interface: GpuCloudletScheduler

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** Define o contrato para escalonamento de tarefas GPU em uma VM.

**ImplementaÃ§Ãµes:** `GpuCloudletSchedulerTimeShared`, `GpuCloudletSchedulerSpaceShared` (futuro)

#### MÃ©todos

```java
/**
 * Inicializa o escalonador com uma GPU especÃ­fica.
 * 
 * @param gpu GPU a ser gerenciada pelo escalonador
 */
void initialize(Gpu gpu);

/**
 * Submete uma tarefa GPU para execuÃ§Ã£o.
 * 
 * @param gpuTask Tarefa GPU a ser executada
 * @return true se a tarefa foi aceita, false caso contrÃ¡rio
 */
boolean submitGpuTask(GpuTask gpuTask);

/**
 * Remove uma tarefa GPU da fila de execuÃ§Ã£o.
 * 
 * @param gpuTask Tarefa a ser removida
 * @return true se a tarefa foi removida, false caso contrÃ¡rio
 */
boolean removeGpuTask(GpuTask gpuTask);

/**
 * Atualiza o escalonamento das tarefas GPU.
 * Chamado periodicamente pelo simulador.
 * 
 * @param currentTime Tempo atual da simulaÃ§Ã£o
 * @return PrÃ³ximo tempo de evento ou Double.MAX_VALUE
 */
double updateGpuTaskProcessing(double currentTime);

/**
 * Retorna a lista de tarefas GPU atualmente em execuÃ§Ã£o.
 * 
 * @return Lista de tarefas em execuÃ§Ã£o
 */
List<GpuTask> getRunningGpuTasks();

/**
 * Retorna a lista de tarefas GPU aguardando execuÃ§Ã£o.
 * 
 * @return Lista de tarefas em espera
 */
List<GpuTask> getWaitingGpuTasks();

/**
 * Retorna a lista de tarefas GPU completadas.
 * 
 * @return Lista de tarefas finalizadas
 */
List<GpuTask> getCompletedGpuTasks();

/**
 * Calcula a utilizaÃ§Ã£o atual da GPU gerenciada.
 * 
 * @return UtilizaÃ§Ã£o em percentual (0-100%)
 */
double getGpuUtilization();

/**
 * Verifica se hÃ¡ tarefas GPU em execuÃ§Ã£o.
 * 
 * @return true se hÃ¡ tarefas em execuÃ§Ã£o, false caso contrÃ¡rio
 */
boolean hasRunningTasks();

/**
 * Retorna a GPU gerenciada por este escalonador.
 * 
 * @return GPU gerenciada
 */
Gpu getGpu();
```

---

### 1.8 Classe: GpuCloudletSchedulerTimeShared

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** ImplementaÃ§Ã£o time-shared de escalonamento GPU (mÃºltiplas tarefas compartilham GPU via time-slicing).

**Relacionamentos:**
- Implementa: `GpuCloudletScheduler`
- Usado por: `GpuEdgeVM`

#### Atributos

```java
/**
 * GPU gerenciada por este escalonador.
 * @visibility private
 * @type Gpu
 */
private Gpu gpu;

/**
 * Lista de tarefas GPU em execuÃ§Ã£o.
 * @visibility private
 * @type List<GpuTask>
 */
private List<GpuTask> runningTasks;

/**
 * Lista de tarefas GPU aguardando execuÃ§Ã£o.
 * @visibility private
 * @type List<GpuTask>
 */
private List<GpuTask> waitingTasks;

/**
 * Lista de tarefas GPU completadas.
 * @visibility private
 * @type List<GpuTask>
 */
private List<GpuTask> completedTasks;

/**
 * Mapa de tempo restante para cada tarefa (taskId -> remaining time).
 * @visibility private
 * @type Map<Integer, Double>
 */
private Map<Integer, Double> taskRemainingTimeMap;

/**
 * Ãšltimo tempo de atualizaÃ§Ã£o do escalonamento.
 * @visibility private
 * @type double
 */
private double previousTime;
```

#### Construtores

```java
/**
 * Construtor padrÃ£o (GPU serÃ¡ definida via initialize()).
 */
public GpuCloudletSchedulerTimeShared()

/**
 * Construtor com GPU especificada.
 * 
 * @param gpu GPU a ser gerenciada
 */
public GpuCloudletSchedulerTimeShared(Gpu gpu)
```

#### MÃ©todos

```java
/**
 * Inicializa o escalonador com uma GPU.
 * 
 * @param gpu GPU a ser gerenciada
 */
@Override
public void initialize(Gpu gpu)

/**
 * Submete uma tarefa GPU para execuÃ§Ã£o.
 * Adiciona Ã  fila de running tasks e redistribui recursos.
 * 
 * @param gpuTask Tarefa GPU a ser executada
 * @return true sempre (time-shared aceita todas as tarefas)
 */
@Override
public boolean submitGpuTask(GpuTask gpuTask)

/**
 * Remove uma tarefa GPU da execuÃ§Ã£o.
 * 
 * @param gpuTask Tarefa a ser removida
 * @return true se removida com sucesso
 */
@Override
public boolean removeGpuTask(GpuTask gpuTask)

/**
 * Atualiza o processamento das tarefas GPU.
 * Divide GFLOPS igualmente entre tarefas ativas.
 * 
 * @param currentTime Tempo atual da simulaÃ§Ã£o
 * @return PrÃ³ximo tempo de evento
 */
@Override
public double updateGpuTaskProcessing(double currentTime)

/**
 * Retorna a lista de tarefas em execuÃ§Ã£o.
 * 
 * @return Lista de tarefas em execuÃ§Ã£o
 */
@Override
public List<GpuTask> getRunningGpuTasks()

/**
 * Retorna a lista de tarefas aguardando.
 * 
 * @return Lista de tarefas em espera
 */
@Override
public List<GpuTask> getWaitingGpuTasks()

/**
 * Retorna a lista de tarefas completadas.
 * 
 * @return Lista de tarefas finalizadas
 */
@Override
public List<GpuTask> getCompletedGpuTasks()

/**
 * Calcula a utilizaÃ§Ã£o da GPU baseada no nÃºmero de tarefas ativas.
 * 
 * @return UtilizaÃ§Ã£o em percentual (0-100%)
 */
@Override
public double getGpuUtilization()

/**
 * Verifica se hÃ¡ tarefas em execuÃ§Ã£o.
 * 
 * @return true se hÃ¡ tarefas em execuÃ§Ã£o
 */
@Override
public boolean hasRunningTasks()

/**
 * Retorna a GPU gerenciada.
 * 
 * @return GPU gerenciada
 */
@Override
public Gpu getGpu()

/**
 * Redistribui os recursos GPU entre tarefas ativas.
 * Implementa time-slicing dividindo GFLOPS igualmente.
 */
private void redistributeGpuResources()

/**
 * Calcula o tempo restante de uma tarefa GPU.
 * 
 * @param gpuTask Tarefa GPU
 * @return Tempo restante em segundos
 */
private double calculateRemainingTime(GpuTask gpuTask)

/**
 * Finaliza uma tarefa GPU e move para completed tasks.
 * 
 * @param gpuTask Tarefa a ser finalizada
 */
private void finishGpuTask(GpuTask gpuTask)
```

---

### 1.9 Classe: GpuEdgeServerManager

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** Gerenciador de infraestrutura edge com suporte a GPU.

**Relacionamentos:**
- Estende: `EdgeServerManager`
- Cria: `GpuEdgeHost`, `GpuEdgeVM`
- Usa: `GpuEdgeVmAllocationPolicy_Custom`

#### Atributos

```java
/**
 * Contador de IDs de hosts.
 * @visibility private
 * @type int
 */
private int hostIdCounter;

/**
 * Contador de IDs de VMs.
 * @visibility private
 * @type int
 */
private int vmIdCounter;
```

#### MÃ©todos

```java
/**
 * Inicializa o gerenciador de servidores GPU.
 */
@Override
public void initialize()

/**
 * Retorna a polÃ­tica de alocaÃ§Ã£o de VMs para datacenters GPU.
 * 
 * @param list Lista de hosts do datacenter
 * @param dataCenterIndex Ãndice do datacenter
 * @return PolÃ­tica de alocaÃ§Ã£o GPU-aware
 */
@Override
public VmAllocationPolicy getVmAllocationPolicy(List<? extends Host> list, 
                                                 int dataCenterIndex)

/**
 * Inicia os datacenters edge com suporte a GPU.
 * LÃª configuraÃ§Ãµes do edge_devices.xml e cria GpuEdgeHosts.
 * 
 * @throws Exception se houver erro na criaÃ§Ã£o dos datacenters
 */
@Override
public void startDatacenters() throws Exception

/**
 * Termina todos os datacenters edge.
 */
@Override
public void terminateDatacenters()

/**
 * Cria a lista de VMs edge com suporte a GPU.
 * LÃª configuraÃ§Ãµes do edge_devices.xml e aloca GPUs conforme necessÃ¡rio.
 * 
 * @param brokerId ID do broker
 */
@Override
public void createVmList(int brokerId)

/**
 * Calcula a utilizaÃ§Ã£o mÃ©dia (CPU + GPU) de todos os edge servers.
 * 
 * @return UtilizaÃ§Ã£o mÃ©dia em percentual (0-100%)
 */
@Override
public double getAvgUtilization()

/**
 * Cria um datacenter edge com hosts GPU.
 * 
 * @param dataCenterIndex Ãndice do datacenter
 * @param datacenterElement Elemento XML com configuraÃ§Ãµes
 * @return Datacenter criado
 * @throws Exception se houver erro na criaÃ§Ã£o
 */
private Datacenter createGpuDatacenter(int dataCenterIndex, 
                                        Element datacenterElement) throws Exception

/**
 * Cria lista de hosts GPU a partir do XML.
 * 
 * @param datacenterElement Elemento XML com configuraÃ§Ãµes de hosts
 * @return Lista de GpuEdgeHosts criados
 */
private List<GpuEdgeHost> createGpuHosts(Element datacenterElement)

/**
 * Cria lista de GPUs a partir do XML.
 * 
 * @param hostElement Elemento XML com configuraÃ§Ãµes de GPUs
 * @return Lista de GPUs criadas
 */
private List<Gpu> createGpuList(Element hostElement)

/**
 * Cria lista de Processing Elements (CPU cores) a partir do XML.
 * 
 * @param hostElement Elemento XML com configuraÃ§Ãµes de PEs
 * @return Lista de PEs criados
 */
private List<Pe> createPeList(Element hostElement)
```

---

### 1.10 Classe: GpuEdgeVmAllocationPolicy_Custom

**Pacote:** `edu.boun.edgecloudsim.edge_server`

**PropÃ³sito:** PolÃ­tica de alocaÃ§Ã£o de VMs com consideraÃ§Ã£o de recursos GPU.

**Relacionamentos:**
- Estende: `EdgeVmAllocationPolicy_Custom`
- Aloca: `GpuEdgeVM` em `GpuEdgeHost`

#### Atributos

```java
/**
 * Ãndice do datacenter gerenciado por esta polÃ­tica.
 * @visibility private
 * @type int
 */
private int dataCenterIndex;
```

#### Construtores

```java
/**
 * Construtor da polÃ­tica de alocaÃ§Ã£o GPU.
 * 
 * @param list Lista de hosts do datacenter
 * @param dataCenterIndex Ãndice do datacenter
 */
public GpuEdgeVmAllocationPolicy_Custom(List<? extends Host> list, 
                                         int dataCenterIndex)
```

#### MÃ©todos

```java
/**
 * Aloca um host para uma VM considerando requisitos GPU.
 * Verifica disponibilidade de GPU antes de alocar a VM.
 * 
 * @param vm VM a ser alocada
 * @return true se a alocaÃ§Ã£o foi bem-sucedida
 */
@Override
public boolean allocateHostForVm(Vm vm)

/**
 * Aloca um host especÃ­fico para uma VM considerando GPU.
 * 
 * @param vm VM a ser alocada
 * @param host Host onde a VM serÃ¡ alocada
 * @return true se a alocaÃ§Ã£o foi bem-sucedida
 */
@Override
public boolean allocateHostForVm(Vm vm, Host host)

/**
 * Desaloca o host de uma VM e libera a GPU associada.
 * 
 * @param vm VM a ser desalocada
 */
@Override
public void deallocateHostForVm(Vm vm)

/**
 * Encontra um host adequado para uma VM considerando recursos GPU.
 * 
 * @param vm VM para a qual buscar host
 * @return Host adequado ou null se nenhum disponÃ­vel
 */
private GpuEdgeHost findSuitableHostForVm(GpuEdgeVM vm)

/**
 * Verifica se um host pode hospedar uma VM com requisitos GPU.
 * 
 * @param host Host a ser verificado
 * @param vm VM com requisitos
 * @return true se o host pode hospedar a VM
 */
private boolean canHostVm(GpuEdgeHost host, GpuEdgeVM vm)

/**
 * Aloca GPU para uma VM em um host especÃ­fico.
 * 
 * @param host Host com GPUs disponÃ­veis
 * @param vm VM que receberÃ¡ a GPU
 * @return true se a alocaÃ§Ã£o GPU foi bem-sucedida
 */
private boolean allocateGpuForVm(GpuEdgeHost host, GpuEdgeVM vm)
```

---

## 2. Diagramas UML Detalhados

### 2.1 Diagrama de Classes: Hierarquia GPU Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        <<Abstract>>                                         â”‚
â”‚                     EdgeServerManager                                       â”‚
â”‚  (edu.boun.edgecloudsim.edge_server)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  # localDatacenters: List<Datacenter>                                       â”‚
â”‚  # vmList: List<List<EdgeVM>>                                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + initialize(): void                                                       â”‚
â”‚  + getVmAllocationPolicy(...): VmAllocationPolicy [abstract]                â”‚
â”‚  + startDatacenters(): void [abstract]                                      â”‚
â”‚  + terminateDatacenters(): void [abstract]                                  â”‚
â”‚  + createVmList(brokerId: int): void [abstract]                             â”‚
â”‚  + getAvgUtilization(): double [abstract]                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–³
                                â”‚ extends
                                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     GpuEdgeServerManager                                    â”‚
â”‚  (edu.boun.edgecloudsim.edge_server)                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - hostIdCounter: int                                                       â”‚
â”‚  - vmIdCounter: int                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + initialize(): void                                                       â”‚
â”‚  + getVmAllocationPolicy(...): VmAllocationPolicy                           â”‚
â”‚  + startDatacenters(): void                                                 â”‚
â”‚  + terminateDatacenters(): void                                             â”‚
â”‚  + createVmList(brokerId: int): void                                        â”‚
â”‚  + getAvgUtilization(): double                                              â”‚
â”‚  - createGpuDatacenter(...): Datacenter                                     â”‚
â”‚  - createGpuHosts(...): List<GpuEdgeHost>                                   â”‚
â”‚  - createGpuList(...): List<Gpu>                                            â”‚
â”‚  - createPeList(...): List<Pe>                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ creates
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼                  â–¼                    â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   GpuEdgeHost      â”‚  â”‚   GpuEdgeVM    â”‚  â”‚ GpuEdgeVmAllocation â”‚
        â”‚                    â”‚  â”‚                â”‚  â”‚   Policy_Custom     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          <<CloudSim>>                â”‚
â”‚            Host                      â”‚
â”‚  (org.cloudbus.cloudsim)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  # id: int                           â”‚
â”‚  # ramProvisioner: RamProvisioner    â”‚
â”‚  # bwProvisioner: BwProvisioner      â”‚
â”‚  # storage: long                     â”‚
â”‚  # peList: List<Pe>                  â”‚
â”‚  # vmScheduler: VmScheduler          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + vmCreate(vm: Vm): boolean         â”‚
â”‚  + vmDestroy(vm: Vm): void           â”‚
â”‚  + getVmList(): List<Vm>             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EdgeHost                   â”‚
â”‚  (edu.boun.edgecloudsim.edge_server) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - location: Location                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + setPlace(location: Location)      â”‚
â”‚  + getLocation(): Location           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GpuEdgeHost                                â”‚
â”‚        (edu.boun.edgecloudsim.edge_server)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - gpuList: List<Gpu>                                        â”‚
â”‚  - gpuProvisioner: GpuProvisioner                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + GpuEdgeHost(id, ..., gpuList, gpuProvisioner)             â”‚
â”‚  + getGpuList(): List<Gpu>                                   â”‚
â”‚  + getGpuProvisioner(): GpuProvisioner                       â”‚
â”‚  + allocateGpuForVm(vm, gpu): boolean                        â”‚
â”‚  + deallocateGpuForVm(vm): void                              â”‚
â”‚  + hasAvailableGpu(): boolean                                â”‚
â”‚  + getAvailableGpu(): Gpu                                    â”‚
â”‚  + getAvgGpuUtilization(): double                            â”‚
â”‚  + getTotalGpuMemory(): long                                 â”‚
â”‚  + vmCreate(vm): boolean [override]                          â”‚
â”‚  + vmDestroy(vm): void [override]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ 1        contains       1..*
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
                    â”‚                                   â”‚
                    â”‚                                   â–¼
                    â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    â”‚            Gpu                 â”‚
                    â”‚                    â”‚  (edu.boun.edgecloudsim.       â”‚
                    â”‚                    â”‚   edge_server)                 â”‚
                    â”‚                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚                    â”‚  - id: int                     â”‚
                    â”‚                    â”‚  - gpuType: String             â”‚
                    â”‚                    â”‚  - cudaCores: int              â”‚
                    â”‚                    â”‚  - gflops: double              â”‚
                    â”‚                    â”‚  - gpuMemory: long             â”‚
                    â”‚                    â”‚  - memoryBandwidth: double     â”‚
                    â”‚                    â”‚  - utilization: double         â”‚
                    â”‚                    â”‚  - usedMemory: long            â”‚
                    â”‚                    â”‚  - allocatedVm: GpuEdgeVM      â”‚
                    â”‚                    â”‚  - host: GpuEdgeHost           â”‚
                    â”‚                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚                    â”‚  + Gpu(id, type, cores, ...)   â”‚
                    â”‚                    â”‚  + getId(): int                â”‚
                    â”‚                    â”‚  + getGflops(): double         â”‚
                    â”‚                    â”‚  + getUtilization(): double    â”‚
                    â”‚                    â”‚  + isAvailable(): boolean      â”‚
                    â”‚                    â”‚  + setAllocatedVm(vm)          â”‚
                    â”‚                    â”‚  + allocateMemory(size): bool  â”‚
                    â”‚                    â”‚  + calculateExecutionTime(...) â”‚
                    â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ uses                                â–³
                    â”‚                                     â”‚ manages
                    â–¼                                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚    <<Interface>>                       â”‚                â”‚
â”‚    GpuProvisioner                      â”‚                â”‚
â”‚  (edu.boun.edgecloudsim.edge_server)   â”‚                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                â”‚
â”‚  + allocateGpuForVm(vm, gpu): boolean  â”‚                â”‚
â”‚  + deallocateGpuForVm(vm): void        â”‚                â”‚
â”‚  + hasAvailableGpu(): boolean          â”‚                â”‚
â”‚  + getAvailableGpu(): Gpu              â”‚                â”‚
â”‚  + getGpuList(): List<Gpu>             â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
                â–³                                         â”‚
                â”‚ implements                              â”‚
                â”‚                                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚         GpuProvisionerSimple                       â”‚    â”‚
â”‚   (edu.boun.edgecloudsim.edge_server)              â”‚    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”‚
â”‚  - gpuList: List<Gpu>                              â”‚â”€â”€â”€â”€â”˜
â”‚  - vmGpuMap: Map<Integer, Gpu>                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + GpuProvisionerSimple(gpuList)                   â”‚
â”‚  + allocateGpuForVm(vm, gpu): boolean              â”‚
â”‚  + deallocateGpuForVm(vm): void                    â”‚
â”‚  + hasAvailableGpu(): boolean                      â”‚
â”‚  + getAvailableGpu(): Gpu                          â”‚
â”‚  + getAverageUtilization(): double                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      <<CloudSim>>              â”‚
â”‚          Vm                    â”‚
â”‚  (org.cloudbus.cloudsim)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  # id: int                     â”‚
â”‚  # userId: int                 â”‚
â”‚  # mips: double                â”‚
â”‚  # numberOfPes: int            â”‚
â”‚  # ram: int                    â”‚
â”‚  # bw: long                    â”‚
â”‚  # size: long                  â”‚
â”‚  # cloudletScheduler           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          EdgeVM                â”‚
â”‚  (edu.boun.edgecloudsim.       â”‚
â”‚   edge_server)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - type: VM_TYPES              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + getVmType(): VM_TYPES       â”‚
â”‚  + reconfigureMips(mips)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GpuEdgeVM                             â”‚
â”‚         (edu.boun.edgecloudsim.edge_server)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - allocatedGpu: Gpu                                     â”‚
â”‚  - gpuCloudletScheduler: GpuCloudletScheduler            â”‚
â”‚  - requiresGpu: boolean                                  â”‚
â”‚  - gpuAllocationMode: GpuAllocationMode                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + GpuEdgeVM(id, ..., gpuScheduler, requiresGpu)         â”‚
â”‚  + setGpu(gpu): void                                     â”‚
â”‚  + getGpu(): Gpu                                         â”‚
â”‚  + hasGpu(): boolean                                     â”‚
â”‚  + requiresGpu(): boolean                                â”‚
â”‚  + getGpuCloudletScheduler(): GpuCloudletScheduler       â”‚
â”‚  + submitGpuTask(task): boolean                          â”‚
â”‚  + getGpuUtilization(): double                           â”‚
â”‚  + getAvailableGpuMemory(): long                         â”‚
â”‚  + reconfigureGpu(gflops): void                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  <<enumeration>>                                         â”‚
â”‚  + GpuAllocationMode                                     â”‚
â”‚    - EXCLUSIVE                                           â”‚
â”‚    - SHARED                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ 1     has     0..1
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
                    â”‚                    â”‚
                    â”‚                    â–¼
                    â”‚                  [Gpu]
                    â”‚
                    â”‚ 1      uses      1
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
                    â”‚                                         â”‚
                    â–¼                                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      <<Interface>>                       â”‚  â”‚    <<Interface>>               â”‚
â”‚      GpuCloudletScheduler                â”‚  â”‚    GpuProvisioner              â”‚
â”‚  (edu.boun.edgecloudsim.edge_server)     â”‚  â”‚                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  + initialize(gpu): void                 â”‚
â”‚  + submitGpuTask(task): boolean          â”‚
â”‚  + removeGpuTask(task): boolean          â”‚
â”‚  + updateGpuTaskProcessing(time): double â”‚
â”‚  + getRunningGpuTasks(): List<GpuTask>   â”‚
â”‚  + getGpuUtilization(): double           â”‚
â”‚  + getGpu(): Gpu                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ implements
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       GpuCloudletSchedulerTimeShared                  â”‚
â”‚   (edu.boun.edgecloudsim.edge_server)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - gpu: Gpu                                           â”‚
â”‚  - runningTasks: List<GpuTask>                        â”‚
â”‚  - waitingTasks: List<GpuTask>                        â”‚
â”‚  - completedTasks: List<GpuTask>                      â”‚
â”‚  - taskRemainingTimeMap: Map<Integer, Double>         â”‚
â”‚  - previousTime: double                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + GpuCloudletSchedulerTimeShared()                   â”‚
â”‚  + GpuCloudletSchedulerTimeShared(gpu)                â”‚
â”‚  + initialize(gpu): void                              â”‚
â”‚  + submitGpuTask(task): boolean                       â”‚
â”‚  + updateGpuTaskProcessing(time): double              â”‚
â”‚  + getGpuUtilization(): double                        â”‚
â”‚  - redistributeGpuResources(): void                   â”‚
â”‚  - finishGpuTask(task): void                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚ manages
                    â”‚ 1      *
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>
                    â”‚                  â”‚
                    â–¼                  â–¼
                  [Gpu]         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                â”‚         GpuTask                  â”‚
                                â”‚  (edu.boun.edgecloudsim.         â”‚
                                â”‚   edge_client)                   â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      <<CloudSim>>              â”‚
â”‚        Cloudlet                â”‚
â”‚  (org.cloudbus.cloudsim)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  # cloudletId: int             â”‚
â”‚  # cloudletLength: long        â”‚
â”‚  # pesNumber: int              â”‚
â”‚  # fileSize: long              â”‚
â”‚  # outputSize: long            â”‚
â”‚  # utilizationModelCpu         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Task                â”‚
â”‚  (edu.boun.edgecloudsim.       â”‚
â”‚   edge_client)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - submittedLocation: Location â”‚
â”‚  - creationTime: double        â”‚
â”‚  - type: int                   â”‚
â”‚  - mobileDeviceId: int         â”‚
â”‚  - hostIndex: int              â”‚
â”‚  - vmIndex: int                â”‚
â”‚  - datacenterId: int           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + Task(deviceId, id, ...)     â”‚
â”‚  + setSubmittedLocation(loc)   â”‚
â”‚  + getMobileDeviceId(): int    â”‚
â”‚  + getTaskType(): int          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    GpuTask                               â”‚
â”‚         (edu.boun.edgecloudsim.edge_client)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - gpuLength: long                                       â”‚
â”‚  - gpuInputData: long                                    â”‚
â”‚  - gpuOutputData: long                                   â”‚
â”‚  - requiredGpuMemory: long                               â”‚
â”‚  - expectedGpuUtilization: double                        â”‚
â”‚  - executedGpuId: int                                    â”‚
â”‚  - gpuDataTransferTime: double                           â”‚
â”‚  - gpuExecutionTime: double                              â”‚
â”‚  - gpuDataBackTime: double                               â”‚
â”‚  - actualGpuUtilization: double                          â”‚
â”‚  - gpuStartTime: double                                  â”‚
â”‚  - gpuFinishTime: double                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + GpuTask(deviceId, id, ..., gpuLength, ...)            â”‚
â”‚  + getGpuLength(): long                                  â”‚
â”‚  + getGpuInputData(): long                               â”‚
â”‚  + getRequiredGpuMemory(): long                          â”‚
â”‚  + getGpuExecutionTime(): double                         â”‚
â”‚  + setGpuDataTransferTime(time): void                    â”‚
â”‚  + setActualGpuUtilization(util): void                   â”‚
â”‚  + getTotalGpuTime(): double                             â”‚
â”‚  + requiresGpu(): boolean                                â”‚
â”‚  + getGpuIntensity(): double                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜




â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           <<CloudSim>>                                   â”‚
â”‚           VmAllocationPolicy                             â”‚
â”‚    (org.cloudbus.cloudsim)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  # hostList: List<Host>                                  â”‚
â”‚  # vmTable: Map<String, Host>                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + allocateHostForVm(vm): boolean [abstract]             â”‚
â”‚  + deallocateHostForVm(vm): void [abstract]              â”‚
â”‚  + getHost(vm): Host                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        EdgeVmAllocationPolicy_Custom                     â”‚
â”‚   (edu.boun.edgecloudsim.edge_server)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - dataCenterIndex: int                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + allocateHostForVm(vm): boolean                        â”‚
â”‚  + deallocateHostForVm(vm): void                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ extends
                â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        GpuEdgeVmAllocationPolicy_Custom                  â”‚
â”‚   (edu.boun.edgecloudsim.edge_server)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  - dataCenterIndex: int                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  + GpuEdgeVmAllocationPolicy_Custom(list, index)         â”‚
â”‚  + allocateHostForVm(vm): boolean [override]             â”‚
â”‚  + deallocateHostForVm(vm): void [override]              â”‚
â”‚  - findSuitableHostForVm(vm): GpuEdgeHost                â”‚
â”‚  - canHostVm(host, vm): boolean                          â”‚
â”‚  - allocateGpuForVm(host, vm): boolean                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2.2 Diagrama de Pacotes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               edu.boun.edgecloudsim.edge_server                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Classes:                                                          â”‚
â”‚    â€¢ EdgeServerManager (abstract)                                  â”‚
â”‚    â€¢ GpuEdgeServerManager                                          â”‚
â”‚    â€¢ EdgeHost                                                      â”‚
â”‚    â€¢ GpuEdgeHost                                                   â”‚
â”‚    â€¢ EdgeVM                                                        â”‚
â”‚    â€¢ GpuEdgeVM                                                     â”‚
â”‚    â€¢ EdgeVmAllocationPolicy_Custom                                 â”‚
â”‚    â€¢ GpuEdgeVmAllocationPolicy_Custom                              â”‚
â”‚    â€¢ Gpu                                                           â”‚
â”‚                                                                    â”‚
â”‚  Interfaces:                                                       â”‚
â”‚    â€¢ GpuProvisioner                                                â”‚
â”‚    â€¢ GpuCloudletScheduler                                          â”‚
â”‚                                                                    â”‚
â”‚  ImplementaÃ§Ãµes:                                                   â”‚
â”‚    â€¢ GpuProvisionerSimple                                          â”‚
â”‚    â€¢ GpuCloudletSchedulerTimeShared                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ uses
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               edu.boun.edgecloudsim.edge_client                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Classes:                                                          â”‚
â”‚    â€¢ Task                                                          â”‚
â”‚    â€¢ GpuTask                                                       â”‚
â”‚    â€¢ MobileDeviceManager (abstract)                                â”‚
â”‚    â€¢ DefaultMobileDeviceManager                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ uses
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               edu.boun.edgecloudsim.core                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Classes:                                                          â”‚
â”‚    â€¢ SimManager                                                    â”‚
â”‚    â€¢ SimSettings                                                   â”‚
â”‚                                                                    â”‚
â”‚  Interfaces:                                                       â”‚
â”‚    â€¢ ScenarioFactory                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                        â”‚ depends on
                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  org.cloudbus.cloudsim                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Classes:                                                          â”‚
â”‚    â€¢ Host                                                          â”‚
â”‚    â€¢ Vm                                                            â”‚
â”‚    â€¢ Cloudlet                                                      â”‚
â”‚    â€¢ Datacenter                                                    â”‚
â”‚    â€¢ VmAllocationPolicy                                            â”‚
â”‚    â€¢ CloudletScheduler                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2.3 Diagrama de Relacionamentos

```
                  GpuEdgeServerManager
                          â”‚
                          â”‚ creates
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                   â”‚               â”‚
                â–¼                   â–¼               â–¼
         GpuEdgeHost         GpuEdgeVM    GpuEdgeVmAllocation
                â”‚                â”‚          Policy_Custom
                â”‚ contains       â”‚ has             â”‚
                â”‚ 1..*           â”‚ 0..1            â”‚ uses
                â–¼                â–¼                 â”‚
              Gpu â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
                â”‚                                  â”‚
                â”‚ managed by                       â”‚
                â–¼                                  â”‚
          GpuProvisioner â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–³
                â”‚ implemented by
                â”‚
          GpuProvisionerSimple


         GpuEdgeVM
              â”‚
              â”‚ uses
              â–¼
     GpuCloudletScheduler â—„â”€â”€â”€â”€â”€ schedules â”€â”€â”€â”€â”€ GpuTask
              â–³                                      â”‚
              â”‚ implemented by                       â”‚ extends
              â”‚                                      â”‚
    GpuCloudletScheduler                            Task
        TimeShared                                   â”‚ extends
                                                     â”‚
                                                  Cloudlet
```

---

## 3. Contratos de Interfaces

### 3.1 Interface: GpuProvisioner

**Objetivo:** Definir contrato para provisionamento de GPUs a VMs.

**JavaDoc Completo:**

```java
package edu.boun.edgecloudsim.edge_server;

import java.util.List;

/**
 * Interface que define o contrato para provisionamento de GPUs a VMs.
 * 
 * <p>Esta interface especifica os mÃ©todos necessÃ¡rios para gerenciar a alocaÃ§Ã£o
 * e desalocaÃ§Ã£o de recursos GPU em hosts edge. ImplementaÃ§Ãµes desta interface
 * sÃ£o responsÃ¡veis por:
 * <ul>
 *   <li>Rastrear disponibilidade de GPUs</li>
 *   <li>Alocar GPUs para VMs com base em requisitos</li>
 *   <li>Desalocar GPUs quando VMs sÃ£o destruÃ­das</li>
 *   <li>Fornecer informaÃ§Ãµes sobre utilizaÃ§Ã£o de GPU</li>
 * </ul>
 * 
 * <p><b>PolÃ­ticas de Provisionamento:</b>
 * <ul>
 *   <li><b>Exclusive Mode:</b> 1 GPU : 1 VM (implementaÃ§Ã£o atual)</li>
 *   <li><b>Shared Mode:</b> 1 GPU : N VMs (implementaÃ§Ã£o futura)</li>
 * </ul>
 * 
 * <p><b>Exemplo de Uso:</b>
 * <pre>
 * GpuProvisioner provisioner = new GpuProvisionerSimple(gpuList);
 * if (provisioner.hasAvailableGpu()) {
 *     Gpu gpu = provisioner.getAvailableGpu();
 *     if (provisioner.allocateGpuForVm(vm, gpu)) {
 *         System.out.println("GPU " + gpu.getId() + " alocada para VM " + vm.getId());
 *     }
 * }
 * </pre>
 * 
 * @author Pabllo Borges Cardoso
 * @version 1.0
 * @since GpuEdgeCloudSim 1.0
 * 
 * @see GpuProvisionerSimple
 * @see GpuEdgeHost
 * @see Gpu
 */
public interface GpuProvisioner {
    
    /**
     * Aloca uma GPU especÃ­fica para uma VM.
     * 
     * <p>Este mÃ©todo tenta alocar a GPU especificada para a VM fornecida.
     * A alocaÃ§Ã£o sÃ³ Ã© bem-sucedida se a GPU estiver disponÃ­vel (nÃ£o alocada).
     * 
     * <p><b>PrÃ©-condiÃ§Ãµes:</b>
     * <ul>
     *   <li>A GPU deve existir na lista gerenciada pelo provisioner</li>
     *   <li>A GPU deve estar disponÃ­vel (isAvailable() == true)</li>
     *   <li>A VM nÃ£o deve ter GPU previamente alocada</li>
     * </ul>
     * 
     * <p><b>PÃ³s-condiÃ§Ãµes (se bem-sucedido):</b>
     * <ul>
     *   <li>GPU.allocatedVm aponta para a VM</li>
     *   <li>GPU.isAvailable() retorna false</li>
     *   <li>Mapeamento VMâ†’GPU Ã© registrado</li>
     * </ul>
     * 
     * @param vm  VM que receberÃ¡ a GPU (nÃ£o-null)
     * @param gpu GPU a ser alocada (nÃ£o-null, disponÃ­vel)
     * @return true se a alocaÃ§Ã£o foi bem-sucedida, false caso contrÃ¡rio
     * 
     * @throws NullPointerException se vm ou gpu forem null
     */
    boolean allocateGpuForVm(GpuEdgeVM vm, Gpu gpu);
    
    /**
     * Desaloca a GPU de uma VM, tornando-a disponÃ­vel para outras VMs.
     * 
     * <p>Remove a associaÃ§Ã£o entre VM e GPU, resetando o estado da GPU
     * e removendo-a do mapeamento interno.
     * 
     * <p><b>PÃ³s-condiÃ§Ãµes:</b>
     * <ul>
     *   <li>GPU.allocatedVm = null</li>
     *   <li>GPU.utilization = 0</li>
     *   <li>GPU.usedMemory = 0</li>
     *   <li>GPU.isAvailable() retorna true</li>
     *   <li>Mapeamento VMâ†’GPU Ã© removido</li>
     * </ul>
     * 
     * @param vm VM da qual a GPU serÃ¡ desalocada (nÃ£o-null)
     * 
     * @throws NullPointerException se vm for null
     */
    void deallocateGpuForVm(GpuEdgeVM vm);
    
    /**
     * Verifica se hÃ¡ pelo menos uma GPU disponÃ­vel no pool.
     * 
     * <p>Uma GPU Ã© considerada disponÃ­vel se nÃ£o estiver alocada para nenhuma VM.
     * 
     * @return true se existe pelo menos uma GPU disponÃ­vel, false caso contrÃ¡rio
     */
    boolean hasAvailableGpu();
    
    /**
     * Retorna uma GPU disponÃ­vel do pool gerenciado.
     * 
     * <p>A estratÃ©gia de seleÃ§Ã£o depende da implementaÃ§Ã£o:
     * <ul>
     *   <li><b>First-Fit:</b> Primeira GPU disponÃ­vel encontrada</li>
     *   <li><b>Best-Fit:</b> GPU com capacidade mais prÃ³xima do requisito</li>
     *   <li><b>Least-Loaded:</b> GPU com menor utilizaÃ§Ã£o atual</li>
     * </ul>
     * 
     * <p><b>Nota:</b> Este mÃ©todo nÃ£o realiza alocaÃ§Ã£o automaticamente.
     * Use {@link #allocateGpuForVm(GpuEdgeVM, Gpu)} apÃ³s obter a GPU.
     * 
     * @return GPU disponÃ­vel ou null se nÃ£o houver nenhuma disponÃ­vel
     */
    Gpu getAvailableGpu();
    
    /**
     * Retorna uma GPU disponÃ­vel com memÃ³ria suficiente para um requisito.
     * 
     * <p>Busca uma GPU que esteja disponÃ­vel E tenha pelo menos a quantidade
     * de memÃ³ria especificada livre.
     * 
     * @param requiredMemory MemÃ³ria mÃ­nima necessÃ¡ria em MB (>= 0)
     * @return GPU disponÃ­vel com memÃ³ria suficiente ou null
     * 
     * @throws IllegalArgumentException se requiredMemory < 0
     */
    Gpu getAvailableGpuWithMemory(long requiredMemory);
    
    /**
     * Retorna a lista completa de GPUs gerenciadas por este provisioner.
     * 
     * <p>A lista retornada inclui tanto GPUs disponÃ­veis quanto alocadas.
     * 
     * @return Lista imutÃ¡vel de todas as GPUs gerenciadas
     */
    List<Gpu> getGpuList();
    
    /**
     * Retorna a lista de GPUs atualmente disponÃ­veis (nÃ£o alocadas).
     * 
     * @return Lista de GPUs disponÃ­veis (possivelmente vazia)
     */
    List<Gpu> getAvailableGpuList();
    
    /**
     * Retorna a lista de GPUs atualmente alocadas a VMs.
     * 
     * @return Lista de GPUs alocadas (possivelmente vazia)
     */
    List<Gpu> getAllocatedGpuList();
}
```

---

### 3.2 Interface: GpuCloudletScheduler

**Objetivo:** Definir contrato para escalonamento de tarefas GPU em uma VM.

**JavaDoc Completo:**

```java
package edu.boun.edgecloudsim.edge_server;

import edu.boun.edgecloudsim.edge_client.GpuTask;
import java.util.List;

/**
 * Interface que define o contrato para escalonamento de tarefas GPU em uma VM.
 * 
 * <p>Esta interface especifica os mÃ©todos necessÃ¡rios para gerenciar a execuÃ§Ã£o
 * de tarefas GPU em uma Ãºnica GPU alocada a uma VM. ImplementaÃ§Ãµes desta interface
 * sÃ£o responsÃ¡veis por:
 * <ul>
 *   <li>Aceitar submissÃ£o de novas tarefas GPU</li>
 *   <li>Escalonar execuÃ§Ã£o de tarefas (space-shared ou time-shared)</li>
 *   <li>Atualizar progresso de tarefas durante a simulaÃ§Ã£o</li>
 *   <li>Calcular utilizaÃ§Ã£o da GPU</li>
 *   <li>Gerenciar filas de tarefas (running, waiting, completed)</li>
 * </ul>
 * 
 * <p><b>PolÃ­ticas de Escalonamento:</b>
 * <ul>
 *   <li><b>Time-Shared:</b> MÃºltiplas tarefas compartilham GPU via time-slicing
 *       (implementaÃ§Ã£o atual: {@link GpuCloudletSchedulerTimeShared})</li>
 *   <li><b>Space-Shared:</b> Uma tarefa por vez, outras aguardam em fila
 *       (implementaÃ§Ã£o futura: GpuCloudletSchedulerSpaceShared)</li>
 * </ul>
 * 
 * <p><b>Fluxo de ExecuÃ§Ã£o:</b>
 * <pre>
 * 1. submitGpuTask() â†’ Tarefa entra no sistema
 * 2. updateGpuTaskProcessing() â†’ Atualiza progresso periodicamente
 * 3. Tarefa completa â†’ Move para completed tasks
 * 4. getCompletedGpuTasks() â†’ Recupera tarefas finalizadas
 * </pre>
 * 
 * <p><b>Exemplo de Uso:</b>
 * <pre>
 * GpuCloudletScheduler scheduler = new GpuCloudletSchedulerTimeShared(gpu);
 * GpuTask task = new GpuTask(...);
 * 
 * if (scheduler.submitGpuTask(task)) {
 *     System.out.println("Tarefa " + task.getCloudletId() + " aceita");
 *     
 *     // Durante simulaÃ§Ã£o
 *     double nextEventTime = scheduler.updateGpuTaskProcessing(CloudSim.clock());
 *     
 *     // Recuperar tarefas completadas
 *     List<GpuTask> completed = scheduler.getCompletedGpuTasks();
 * }
 * </pre>
 * 
 * @author Pabllo Borges Cardoso
 * @version 1.0
 * @since GpuEdgeCloudSim 1.0
 * 
 * @see GpuCloudletSchedulerTimeShared
 * @see GpuTask
 * @see GpuEdgeVM
 */
public interface GpuCloudletScheduler {
    
    /**
     * Inicializa o escalonador com uma GPU especÃ­fica.
     * 
     * <p>Este mÃ©todo deve ser chamado antes de qualquer operaÃ§Ã£o de escalonamento.
     * Define a GPU que serÃ¡ gerenciada por este escalonador.
     * 
     * <p><b>PrÃ©-condiÃ§Ãµes:</b>
     * <ul>
     *   <li>GPU nÃ£o deve ser null</li>
     *   <li>MÃ©todo deve ser chamado apenas uma vez</li>
     * </ul>
     * 
     * @param gpu GPU a ser gerenciada pelo escalonador (nÃ£o-null)
     * 
     * @throws NullPointerException se gpu for null
     * @throws IllegalStateException se jÃ¡ foi inicializado
     */
    void initialize(Gpu gpu);
    
    /**
     * Submete uma tarefa GPU para execuÃ§Ã£o.
     * 
     * <p>A tarefa Ã© adicionada ao escalonador e seu processamento Ã© iniciado
     * conforme a polÃ­tica de escalonamento implementada.
     * 
     * <p><b>Comportamento por PolÃ­tica:</b>
     * <ul>
     *   <li><b>Time-Shared:</b> Tarefa sempre aceita, GFLOPS redistribuÃ­do</li>
     *   <li><b>Space-Shared:</b> Tarefa aceita sÃ³ se GPU livre, senÃ£o enfileira</li>
     * </ul>
     * 
     * <p><b>PrÃ©-condiÃ§Ãµes:</b>
     * <ul>
     *   <li>Escalonador deve estar inicializado</li>
     *   <li>gpuTask nÃ£o deve ser null</li>
     *   <li>gpuTask.requiresGpu() deve retornar true</li>
     * </ul>
     * 
     * @param gpuTask Tarefa GPU a ser executada (nÃ£o-null)
     * @return true se a tarefa foi aceita, false caso contrÃ¡rio
     * 
     * @throws NullPointerException se gpuTask for null
     * @throws IllegalStateException se escalonador nÃ£o inicializado
     */
    boolean submitGpuTask(GpuTask gpuTask);
    
    /**
     * Remove uma tarefa GPU da fila de execuÃ§Ã£o.
     * 
     * <p>Cancela a execuÃ§Ã£o de uma tarefa antes de sua conclusÃ£o.
     * A tarefa Ã© removida das filas (running ou waiting) mas nÃ£o Ã©
     * adicionada Ã  fila completed.
     * 
     * @param gpuTask Tarefa a ser removida (nÃ£o-null)
     * @return true se a tarefa foi removida com sucesso, false se nÃ£o encontrada
     * 
     * @throws NullPointerException se gpuTask for null
     */
    boolean removeGpuTask(GpuTask gpuTask);
    
    /**
     * Atualiza o processamento das tarefas GPU.
     * 
     * <p>MÃ©todo chamado periodicamente pelo simulador para avanÃ§ar o progresso
     * das tarefas em execuÃ§Ã£o. Calcula quanto trabalho foi realizado desde a
     * Ãºltima atualizaÃ§Ã£o e move tarefas completadas para a fila appropriada.
     * 
     * <p><b>Responsabilidades:</b>
     * <ul>
     *   <li>Calcular delta de tempo: currentTime - previousTime</li>
     *   <li>Atualizar progresso de cada tarefa em execuÃ§Ã£o</li>
     *   <li>Identificar tarefas completadas</li>
     *   <li>Mover tarefas completadas para fila completed</li>
     *   <li>Atualizar utilizaÃ§Ã£o da GPU</li>
     *   <li>Retornar prÃ³ximo tempo de evento</li>
     * </ul>
     * 
     * @param currentTime Tempo atual da simulaÃ§Ã£o em segundos
     * @return PrÃ³ximo tempo onde ocorrerÃ¡ conclusÃ£o de tarefa,
     *         ou Double.MAX_VALUE se nÃ£o hÃ¡ tarefas em execuÃ§Ã£o
     * 
     * @throws IllegalArgumentException se currentTime < previousTime
     */
    double updateGpuTaskProcessing(double currentTime);
    
    /**
     * Retorna a lista de tarefas GPU atualmente em execuÃ§Ã£o.
     * 
     * <p>Tarefas nesta lista estÃ£o ativamente consumindo recursos da GPU.
     * 
     * @return Lista de tarefas em execuÃ§Ã£o (nÃ£o-null, possivelmente vazia)
     */
    List<GpuTask> getRunningGpuTasks();
    
    /**
     * Retorna a lista de tarefas GPU aguardando execuÃ§Ã£o.
     * 
     * <p>AplicÃ¡vel principalmente para polÃ­ticas space-shared onde tarefas
     * podem ficar enfileiradas aguardando liberaÃ§Ã£o da GPU.
     * 
     * @return Lista de tarefas em espera (nÃ£o-null, possivelmente vazia)
     */
    List<GpuTask> getWaitingGpuTasks();
    
    /**
     * Retorna a lista de tarefas GPU completadas.
     * 
     * <p>Tarefas nesta lista finalizaram sua execuÃ§Ã£o e aguardam coleta
     * pelo gerenciador de tarefas.
     * 
     * @return Lista de tarefas finalizadas (nÃ£o-null, possivelmente vazia)
     */
    List<GpuTask> getCompletedGpuTasks();
    
    /**
     * Calcula a utilizaÃ§Ã£o atual da GPU gerenciada.
     * 
     * <p>FÃ³rmula de cÃ¡lculo varia por implementaÃ§Ã£o:
     * <ul>
     *   <li><b>Time-Shared:</b> min(100, (numTasks / maxConcurrentTasks) * 100)</li>
     *   <li><b>Space-Shared:</b> 100 se tem tarefa, 0 caso contrÃ¡rio</li>
     * </ul>
     * 
     * @return UtilizaÃ§Ã£o em percentual (0-100%)
     */
    double getGpuUtilization();
    
    /**
     * Verifica se hÃ¡ tarefas GPU em execuÃ§Ã£o.
     * 
     * <p>Ãštil para determinar se a GPU estÃ¡ ociosa.
     * 
     * @return true se hÃ¡ pelo menos uma tarefa em execuÃ§Ã£o, false caso contrÃ¡rio
     */
    boolean hasRunningTasks();
    
    /**
     * Retorna a GPU gerenciada por este escalonador.
     * 
     * @return GPU gerenciada ou null se nÃ£o inicializado
     */
    Gpu getGpu();
}
```

---

## 4. Diagramas de SequÃªncia

### 4.1 Fluxo: CriaÃ§Ã£o de Infraestrutura GPU

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚MainApp â”‚    â”‚SimManager  â”‚    â”‚GpuEdgeServerManager  â”‚   â”‚GpuEdgeHost  â”‚    â”‚GpuEdgeVM  â”‚  â”‚Gpu   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”˜
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚ new SimManager(factory)              â”‚                      â”‚                 â”‚            â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚ factory.getEdgeServerManager()             â”‚                 â”‚            â”‚
    â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚    new GpuEdgeServerManager()              â”‚                 â”‚            â”‚
    â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚ startSimulation()                    â”‚                      â”‚                 â”‚            â”‚
    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚ startDatacenters()  â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚ [LÃª edge_devices.xml]                  â”‚            â”‚
    â”‚                â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚ createGpuHosts()     â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚ createGpuList()             â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚ new Gpu()  â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚ new GpuEdgeHost(gpuList)    â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚ createGpuDatacenter()â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚ createVmList(brokerId)                     â”‚                 â”‚            â”‚
    â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚ [LÃª edge_devices.xml]                  â”‚            â”‚
    â”‚                â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚          â”‚           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚  new GpuEdgeVM()â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚ getAvailableGpu()    â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚ allocateGpuForVm(vm, gpu)              â”‚            â”‚
    â”‚                â”‚                     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚ setAllocatedVm()
    â”‚                â”‚                     â”‚                      â”‚                 â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚  setGpu(gpu)    â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                 â”‚            â”‚
    â”‚                â”‚                     â”‚                      â”‚                 â”‚            â”‚
    â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                     â”‚                      â”‚                 â”‚            â”‚
```

**DescriÃ§Ã£o:**
1. **MainApp** cria **SimManager** com factory
2. **SimManager** obtÃ©m **GpuEdgeServerManager** via factory
3. **SimManager** chama **startDatacenters()**
4. **GpuEdgeServerManager** lÃª **edge_devices.xml**
5. Para cada host, cria lista de **Gpu** objects
6. Cria **GpuEdgeHost** com lista de GPUs
7. **SimManager** chama **createVmList()**
8. Para cada VM que requer GPU:
   - Cria **GpuEdgeVM**
   - ObtÃ©m GPU disponÃ­vel
   - Aloca GPU para a VM

---

### 4.2 Fluxo: AlocaÃ§Ã£o de GPU para VM

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”
â”‚GpuEdgeVmAllocation       â”‚   â”‚GpuEdgeHost            â”‚   â”‚GpuProvisionerâ”‚  â”‚Gpu   â”‚
â”‚Policy_Custom             â”‚   â”‚                       â”‚   â”‚              â”‚  â”‚      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”˜
           â”‚                               â”‚                      â”‚              â”‚
           â”‚ allocateHostForVm(vm)         â”‚                      â”‚              â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚                      â”‚              â”‚
           â”‚          â”‚ [Verifica se VM    â”‚                      â”‚              â”‚
           â”‚          â”‚  requer GPU]       â”‚                      â”‚              â”‚
           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚                      â”‚              â”‚
           â”‚                               â”‚                      â”‚              â”‚
           â”‚ findSuitableHostForVm(vm)     â”‚                      â”‚              â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚ hasAvailableGpu()  â”‚                      â”‚              â”‚
           â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚ hasAvailableGpu()    â”‚              â”‚
           â”‚          â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚ [Verifica    â”‚
           â”‚          â”‚                    â”‚                      â”‚  GPUs        â”‚
           â”‚          â”‚                    â”‚                      â”‚  disponÃ­veis]â”‚
           â”‚          â”‚                    â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”       â”‚
           â”‚          â”‚                    â”‚                      â”‚      â”‚       â”‚
           â”‚          â”‚                    â”‚                      â”‚<â”€â”€â”€â”€â”€â”˜       â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚              â”‚
           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚                      â”‚              â”‚
           â”‚  [Host adequado encontrado]   â”‚                      â”‚              â”‚
           â”‚                               â”‚                      â”‚              â”‚
           â”‚ allocateGpuForVm(host, vm)    â”‚                      â”‚              â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚ getAvailableGpu()  â”‚                      â”‚              â”‚
           â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚ getAvailableGpu()    â”‚              â”‚
           â”‚          â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚ [Retorna 1Âª  â”‚
           â”‚          â”‚                    â”‚                      â”‚  GPU livre]  â”‚
           â”‚          â”‚                    â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”       â”‚
           â”‚          â”‚                    â”‚                      â”‚      â”‚       â”‚
           â”‚          â”‚                    â”‚                      â”‚<â”€â”€â”€â”€â”€â”˜       â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚ allocateGpuForVm(vm, gpu)                 â”‚              â”‚
           â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚ allocateGpuForVm(vm, gpu)           â”‚
           â”‚          â”‚                    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚ isAvailable()â”‚
           â”‚          â”‚                    â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
           â”‚          â”‚                    â”‚                      â”‚  true        â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚ setAllocatedVm(vm)
           â”‚          â”‚                    â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
           â”‚          â”‚                    â”‚                      â”‚  void        â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚
           â”‚          â”‚                    â”‚  true                â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚              â”‚
           â”‚          â”‚  true              â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚          â”‚ vm.setGpu(gpu)     â”‚                      â”‚              â”‚
           â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚                      â”‚              â”‚
           â”‚          â”‚          â”‚         â”‚                      â”‚              â”‚
           â”‚          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                      â”‚              â”‚
           â”‚          â”‚                    â”‚                      â”‚              â”‚
           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚                      â”‚              â”‚
           â”‚  true                         â”‚                      â”‚              â”‚
           â”‚                               â”‚                      â”‚              â”‚
           â”‚ host.vmCreate(vm)             â”‚                      â”‚              â”‚
           â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚              â”‚
           â”‚                               â”‚                      â”‚              â”‚
           â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚              â”‚
           â”‚  true                         â”‚                      â”‚              â”‚
```

**DescriÃ§Ã£o:**
1. **GpuEdgeVmAllocationPolicy_Custom** recebe requisiÃ§Ã£o de alocaÃ§Ã£o
2. Verifica se a VM requer GPU
3. Busca host adequado com **findSuitableHostForVm()**
4. Verifica se o host tem GPU disponÃ­vel via **hasAvailableGpu()**
5. ObtÃ©m GPU disponÃ­vel via **getAvailableGpu()**
6. Aloca GPU para VM via **allocateGpuForVm()**
7. **GpuProvisioner** verifica disponibilidade e marca GPU como alocada
8. VM Ã© criada no host com GPU alocada

---

### 4.3 Fluxo: ExecuÃ§Ã£o de GpuTask

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”
â”‚MobileDevice      â”‚   â”‚GpuEdgeVM     â”‚    â”‚GpuCloudletSchedulerâ”‚   â”‚GpuTask   â”‚   â”‚Gpu  â”‚
â”‚Manager           â”‚   â”‚              â”‚    â”‚TimeShared          â”‚   â”‚          â”‚   â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”˜
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚ submitTask(gpuTask)                      â”‚                    â”‚           â”‚
          â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚ submitGpuTask(gpuTask)                    â”‚           â”‚
          â”‚                   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ [Adiciona Ã         â”‚           â”‚
          â”‚                   â”‚                      â”‚  runningTasks]     â”‚           â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ redistributeGpuResources()     â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ setGpuStartTime()  â”‚           â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                    â”‚           â”‚
          â”‚                   â”‚  true                â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                    â”‚           â”‚
          â”‚  true             â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚ [Tempo passa - SimManager chama updateGpuTaskProcessing()]    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚ updateGpuTaskProcessing(currentTime)      â”‚           â”‚
          â”‚                   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ [Calcula delta     â”‚           â”‚
          â”‚                   â”‚                      â”‚  de tempo]         â”‚           â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ getGflops()        â”‚           â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
          â”‚                   â”‚                      â”‚  gflops            â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ [Para cada tarefa, â”‚           â”‚
          â”‚                   â”‚                      â”‚  calcula trabalho  â”‚           â”‚
          â”‚                   â”‚                      â”‚  realizado]        â”‚           â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ [Tarefa completou?]â”‚           â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ finishGpuTask(gpuTask)         â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚ setGpuFinishTime()  â”‚
          â”‚                   â”‚                      â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚ setActualGpuUtilization()
          â”‚                   â”‚                      â”‚          â”‚â”€â”€â”€â”€â”€â”€â”€â”€>â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚         â”‚           â”‚
          â”‚                   â”‚                      â”‚          â”‚ [Move para          â”‚
          â”‚                   â”‚                      â”‚          â”‚  completedTasks]    â”‚
          â”‚                   â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚ setUtilization()   â”‚           â”‚
          â”‚                   â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                    â”‚           â”‚
          â”‚                   â”‚  nextEventTime       â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚ getCompletedGpuTasks()                    â”‚           â”‚
          â”‚                   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                    â”‚           â”‚
          â”‚                   â”‚                      â”‚                    â”‚           â”‚
          â”‚                   â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                    â”‚           â”‚
          â”‚                   â”‚  List<GpuTask>       â”‚                    â”‚           â”‚
```

**DescriÃ§Ã£o:**
1. **MobileDeviceManager** submete **GpuTask** para **GpuEdgeVM**
2. **GpuEdgeVM** delega para **GpuCloudletSchedulerTimeShared**
3. Scheduler adiciona tarefa Ã  fila **runningTasks**
4. Redistributes GPU resources (time-slicing)
5. Define tempo de inÃ­cio da tarefa GPU
6. Durante simulaÃ§Ã£o, **updateGpuTaskProcessing()** Ã© chamado periodicamente
7. Calcula trabalho realizado baseado em:
   - Delta de tempo
   - GFLOPS da GPU
   - NÃºmero de tarefas compartilhando GPU (time-shared)
8. Quando tarefa completa:
   - Define tempo de fim
   - Calcula utilizaÃ§Ã£o real
   - Move para **completedTasks**
9. **MobileDeviceManager** recupera tarefas completadas

---

### 4.4 Fluxo: DesalocaÃ§Ã£o de Recursos

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”
â”‚SimManager        â”‚   â”‚GpuEdgeVmAllocation   â”‚   â”‚GpuEdgeHost  â”‚   â”‚GpuProvisionerâ”‚   â”‚Gpu  â”‚
â”‚                  â”‚   â”‚Policy_Custom         â”‚   â”‚             â”‚   â”‚              â”‚   â”‚     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”˜
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚ vmDestroy(vm)          â”‚                      â”‚                 â”‚              â”‚
         â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚ deallocateHostForVm(vm)                â”‚              â”‚
         â”‚                        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚ [Verifica se VM â”‚              â”‚
         â”‚                        â”‚                      â”‚  tem GPU]       â”‚              â”‚
         â”‚                        â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”          â”‚              â”‚
         â”‚                        â”‚                      â”‚      â”‚          â”‚              â”‚
         â”‚                        â”‚                      â”‚<â”€â”€â”€â”€â”€â”˜          â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚ deallocateGpuForVm(vm)         â”‚
         â”‚                        â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚ [Encontra GPUâ”‚
         â”‚                        â”‚                      â”‚                 â”‚  alocada]    â”‚
         â”‚                        â”‚                      â”‚                 â”‚â”€â”€â”€â”€â”€â”€â”       â”‚
         â”‚                        â”‚                      â”‚                 â”‚      â”‚       â”‚
         â”‚                        â”‚                      â”‚                 â”‚<â”€â”€â”€â”€â”€â”˜       â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚ reset()      â”‚
         â”‚                        â”‚                      â”‚                 â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚ [GPU fields: â”‚
         â”‚                        â”‚                      â”‚                 â”‚  allocatedVm=null
         â”‚                        â”‚                      â”‚                 â”‚  utilization=0
         â”‚                        â”‚                      â”‚                 â”‚  usedMemory=0]
         â”‚                        â”‚                      â”‚                 â”‚<â”€â”€â”€â”€â”€â”€â”      â”‚
         â”‚                        â”‚                      â”‚                 â”‚       â”‚      â”‚
         â”‚                        â”‚                      â”‚                 â”‚<â”€â”€â”€â”€â”€â”€â”˜      â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚ vmDestroy(vm)   â”‚              â”‚
         â”‚                        â”‚                      â”‚â”€â”€â”€â”€â”€â”€â”          â”‚              â”‚
         â”‚                        â”‚                      â”‚      â”‚          â”‚              â”‚
         â”‚                        â”‚                      â”‚<â”€â”€â”€â”€â”€â”˜          â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚                        â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                 â”‚              â”‚
         â”‚                        â”‚                      â”‚                 â”‚              â”‚
         â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                      â”‚                 â”‚              â”‚
         â”‚  void                  â”‚                      â”‚                 â”‚              â”‚
```

**DescriÃ§Ã£o:**
1. **SimManager** solicita destruiÃ§Ã£o de VM
2. **GpuEdgeVmAllocationPolicy_Custom** recebe **deallocateHostForVm()**
3. Verifica se a VM possui GPU alocada
4. Se sim, chama **deallocateGpuForVm()** no **GpuEdgeHost**
5. **GpuEdgeHost** delega para **GpuProvisioner**
6. **GpuProvisioner** encontra a GPU alocada para a VM
7. Chama **reset()** na GPU para limpar estado:
   - `allocatedVm = null`
   - `utilization = 0`
   - `usedMemory = 0`
8. Remove mapeamento VMâ†’GPU
9. GPU fica disponÃ­vel para novas alocaÃ§Ãµes
10. Host destrÃ³i a VM normalmente

---

## 5. Exemplos de Uso

### 5.1 Criando GpuEdgeServerManager Personalizado

```java
package edu.boun.edgecloudsim.applications.gpu_app;

import edu.boun.edgecloudsim.core.ScenarioFactory;
import edu.boun.edgecloudsim.edge_server.EdgeServerManager;
import edu.boun.edgecloudsim.edge_server.GpuEdgeServerManager;

/**
 * Factory personalizada para cenÃ¡rios com suporte a GPU.
 */
public class GpuScenarioFactory implements ScenarioFactory {
    private int numOfMobileDevice;
    private double simulationTime;
    private String orchestratorPolicy;
    private String simScenario;
    
    public GpuScenarioFactory(int _numOfMobileDevice,
                              double _simulationTime,
                              String _orchestratorPolicy,
                              String _simScenario) {
        this.numOfMobileDevice = _numOfMobileDevice;
        this.simulationTime = _simulationTime;
        this.orchestratorPolicy = _orchestratorPolicy;
        this.simScenario = _simScenario;
    }
    
    @Override
    public EdgeServerManager getEdgeServerManager() {
        // Retorna implementaÃ§Ã£o GPU em vez da padrÃ£o
        return new GpuEdgeServerManager();
    }
    
    // ... outros mÃ©todos factory
}
```

**Uso:**

```java
public class MainApp {
    public static void main(String[] args) throws Exception {
        // Inicializa CloudSim
        CloudSim.init(numBrokers, calendar, traceFlag);
        
        // Cria factory GPU
        ScenarioFactory factory = new GpuScenarioFactory(
            numMobileDevices,
            simulationTime,
            "GPU_AWARE_ORCHESTRATOR",
            "DEEP_LEARNING_INFERENCE"
        );
        
        // Cria SimManager com factory GPU
        SimManager simManager = new SimManager(factory, numMobileDevices, simScenario);
        
        // Inicia simulaÃ§Ã£o
        simManager.startSimulation();
    }
}
```

---

### 5.2 Configurando edge_devices.xml com GPUs

```xml
<?xml version="1.0"?>
<edge_devices>
    <datacenter arch="x86" os="Linux" vmm="Xen">
        <!-- Custos do datacenter -->
        <costPerBw>0.1</costPerBw>
        <costPerSec>3.0</costPerSec>
        <costPerMem>0.05</costPerMem>
        <costPerStorage>0.1</costPerStorage>
        
        <!-- LocalizaÃ§Ã£o geogrÃ¡fica -->
        <location>
            <x_pos>1</x_pos>
            <y_pos>1</y_pos>
            <wlan_id>0</wlan_id>
            <attractiveness>5</attractiveness>
        </location>
        
        <hosts>
            <host>
                <!-- Recursos CPU tradicionais -->
                <core>16</core>
                <mips>80000</mips>
                <ram>32000</ram>
                <storage>100000</storage>
                
                <!-- â­ NOVO: ConfiguraÃ§Ã£o de GPUs -->
                <gpus>
                    <gpu>
                        <gpu_id>0</gpu_id>
                        <gpu_type>NVIDIA_T4</gpu_type>
                        <cuda_cores>2560</cuda_cores>
                        <gflops>8100</gflops>
                        <gpu_memory>16000</gpu_memory>
                        <memory_bandwidth>320</memory_bandwidth>
                    </gpu>
                    <gpu>
                        <gpu_id>1</gpu_id>
                        <gpu_type>NVIDIA_A100</gpu_type>
                        <cuda_cores>6912</cuda_cores>
                        <gflops>19500</gflops>
                        <gpu_memory>40000</gpu_memory>
                        <memory_bandwidth>1555</memory_bandwidth>
                    </gpu>
                </gpus>
                
                <!-- VMs com suporte a GPU -->
                <VMs>
                    <!-- VM com GPU exclusiva -->
                    <VM vmm="Xen">
                        <core>4</core>
                        <mips>20000</mips>
                        <ram>8000</ram>
                        <storage>50000</storage>
                        <!-- â­ NOVO: Requisitos GPU -->
                        <requires_gpu>true</requires_gpu>
                        <gpu_allocation_mode>EXCLUSIVE</gpu_allocation_mode>
                    </VM>
                    
                    <!-- VM sem GPU -->
                    <VM vmm="Xen">
                        <core>4</core>
                        <mips>20000</mips>
                        <ram>8000</ram>
                        <storage>50000</storage>
                        <requires_gpu>false</requires_gpu>
                    </VM>
                    
                    <!-- VM com GPU compartilhada (futuro) -->
                    <VM vmm="Xen">
                        <core>2</core>
                        <mips>10000</mips>
                        <ram>4000</ram>
                        <storage>25000</storage>
                        <requires_gpu>true</requires_gpu>
                        <gpu_allocation_mode>SHARED</gpu_allocation_mode>
                    </VM>
                </VMs>
            </host>
        </hosts>
    </datacenter>
</edge_devices>
```

---

### 5.3 Configurando applications.xml com Tarefas GPU

```xml
<?xml version="1.0"?>
<applications>
    <!-- AplicaÃ§Ã£o com processamento intensivo em GPU -->
    <application name="DEEP_LEARNING_INFERENCE">
        <usage_percentage>30</usage_percentage>
        <prob_cloud_selection>10</prob_cloud_selection>
        <poisson_interarrival>5</poisson_interarrival>
        <delay_sensitivity>1</delay_sensitivity>
        <active_period>60</active_period>
        <idle_period>30</idle_period>
        
        <!-- Requisitos tradicionais CPU -->
        <data_upload>5000</data_upload>
        <data_download>500</data_download>
        <task_length>50000</task_length>
        <required_core>2</required_core>
        <vm_utilization_on_edge>10</vm_utilization_on_edge>
        <vm_utilization_on_cloud>0.8</vm_utilization_on_cloud>
        <vm_utilization_on_mobile>20</vm_utilization_on_mobile>
        
        <!-- â­ NOVO: Requisitos GPU -->
        <requires_gpu>true</requires_gpu>
        <gpu_length>150000</gpu_length>              <!-- GFLOPs -->
        <gpu_input_data>2000</gpu_input_data>        <!-- MB -->
        <gpu_output_data>100</gpu_output_data>       <!-- MB -->
        <required_gpu_memory>4000</required_gpu_memory> <!-- MB -->
        <expected_gpu_utilization>80</expected_gpu_utilization> <!-- % -->
    </application>
    
    <!-- AplicaÃ§Ã£o tradicional sem GPU -->
    <application name="WEB_BROWSING">
        <usage_percentage>40</usage_percentage>
        <prob_cloud_selection>30</prob_cloud_selection>
        <poisson_interarrival>10</poisson_interarrival>
        <delay_sensitivity>2</delay_sensitivity>
        <active_period>120</active_period>
        <idle_period>60</idle_period>
        
        <data_upload>1000</data_upload>
        <data_download>500</data_download>
        <task_length>10000</task_length>
        <required_core>1</required_core>
        <vm_utilization_on_edge>5</vm_utilization_on_edge>
        
        <!-- Sem requisitos GPU -->
        <requires_gpu>false</requires_gpu>
    </application>
    
    <!-- AplicaÃ§Ã£o hÃ­brida CPU+GPU -->
    <application name="VIDEO_TRANSCODING">
        <usage_percentage>20</usage_percentage>
        <prob_cloud_selection>20</prob_cloud_selection>
        <poisson_interarrival>8</poisson_interarrival>
        <delay_sensitivity>3</delay_sensitivity>
        <active_period>90</active_period>
        <idle_period>45</idle_period>
        
        <!-- Processamento CPU significativo -->
        <data_upload>10000</data_upload>
        <data_download>8000</data_download>
        <task_length>100000</task_length>
        <required_core>4</required_core>
        <vm_utilization_on_edge>15</vm_utilization_on_edge>
        
        <!-- + Processamento GPU moderado -->
        <requires_gpu>true</requires_gpu>
        <gpu_length>80000</gpu_length>
        <gpu_input_data>5000</gpu_input_data>
        <gpu_output_data>5000</gpu_output_data>
        <required_gpu_memory>6000</required_gpu_memory>
        <expected_gpu_utilization>60</expected_gpu_utilization>
    </application>
</applications>
```

---

### 5.4 Criando e Submetendo GpuTask

```java
package edu.boun.edgecloudsim.applications.gpu_app;

import edu.boun.edgecloudsim.edge_client.GpuTask;
import edu.boun.edgecloudsim.edge_client.CpuUtilizationModel_Custom;
import org.cloudbus.cloudsim.UtilizationModelFull;

/**
 * Gerador de tarefas GPU personalizado.
 */
public class GpuLoadGenerator extends LoadGeneratorModel {
    
    @Override
    public void initializeModel() {
        // InicializaÃ§Ã£o
    }
    
    /**
     * Cria uma GpuTask com requisitos CPU e GPU.
     */
    private GpuTask createGpuTask(int mobileDeviceId, int taskType) {
        // Obter configuraÃ§Ãµes da aplicaÃ§Ã£o
        int taskId = taskIdCounter++;
        
        // Requisitos CPU (padrÃ£o EdgeCloudSim)
        long cloudletLength = 50000;      // MI
        int pesNumber = 2;                 // Cores
        long cloudletFileSize = 5000;     // bytes
        long cloudletOutputSize = 500;    // bytes
        
        // Requisitos GPU (novo)
        long gpuLength = 150000;           // GFLOPs
        long gpuInputData = 2000;          // MB
        long gpuOutputData = 100;          // MB
        long requiredGpuMemory = 4000;     // MB
        
        // Modelos de utilizaÃ§Ã£o
        CpuUtilizationModel_Custom cpuModel = 
            new CpuUtilizationModel_Custom(taskType, 
                SimSettings.TYPES.EDGE_DATACENTER);
        UtilizationModelFull ramModel = new UtilizationModelFull();
        UtilizationModelFull bwModel = new UtilizationModelFull();
        
        // Criar GpuTask
        GpuTask gpuTask = new GpuTask(
            mobileDeviceId,
            taskId,
            cloudletLength,
            pesNumber,
            cloudletFileSize,
            cloudletOutputSize,
            cpuModel,
            ramModel,
            bwModel,
            gpuLength,
            gpuInputData,
            gpuOutputData,
            requiredGpuMemory
        );
        
        // Configurar tipo de tarefa
        gpuTask.setTaskType(taskType);
        gpuTask.setExpectedGpuUtilization(80.0);
        
        return gpuTask;
    }
    
    /**
     * Submete tarefa GPU para execuÃ§Ã£o.
     */
    public void submitTask(GpuTask gpuTask) {
        // Orquestrador decide para onde enviar
        int targetDatacenterId = edgeOrchestrator.getDeviceToOffload(gpuTask);
        int targetVmId = edgeOrchestrator.getVmToOffload(gpuTask, targetDatacenterId);
        
        // Define associaÃ§Ãµes
        gpuTask.setAssociatedDatacenterId(targetDatacenterId);
        gpuTask.setAssociatedVmId(targetVmId);
        
        // Envia para o broker
        schedule(
            SimManager.getInstance().getEdgeServerManager().getDatacenterList().get(0).getId(),
            0,
            CREATE_TASK_NOW,
            gpuTask
        );
    }
}
```

---

### 5.5 Processando GpuTask em GpuEdgeVM

```java
package edu.boun.edgecloudsim.edge_client;

import edu.boun.edgecloudsim.core.SimManager;
import edu.boun.edgecloudsim.edge_server.GpuEdgeVM;
import org.cloudbus.cloudsim.core.CloudSim;

/**
 * Gerenciador de dispositivos mÃ³veis com suporte a GpuTask.
 */
public class GpuMobileDeviceManager extends MobileDeviceManager {
    
    /**
     * Processa submissÃ£o de tarefa (GPU ou tradicional).
     */
    @Override
    public void submitTask(Task task) {
        if (task instanceof GpuTask) {
            submitGpuTask((GpuTask) task);
        } else {
            super.submitTask(task);
        }
    }
    
    /**
     * Submete GpuTask para VM apropriada.
     */
    private void submitGpuTask(GpuTask gpuTask) {
        // ObtÃ©m VM de destino
        int vmId = gpuTask.getAssociatedVmId();
        int datacenterId = gpuTask.getAssociatedDatacenterId();
        
        GpuEdgeVM vm = (GpuEdgeVM) SimManager.getInstance()
            .getEdgeServerManager()
            .getVmList(datacenterId)
            .get(vmId);
        
        // Verifica se VM tem GPU (se tarefa requer)
        if (gpuTask.requiresGpu() && !vm.hasGpu()) {
            SimLogger.printLine(CloudSim.clock() + 
                ": Task #" + gpuTask.getCloudletId() + 
                " FAILED - VM #" + vmId + " has no GPU");
            gpuTask.setCloudletStatus(Cloudlet.FAILED);
            return;
        }
        
        // Verifica memÃ³ria GPU disponÃ­vel
        if (gpuTask.requiresGpu()) {
            long availableMemory = vm.getAvailableGpuMemory();
            if (availableMemory < gpuTask.getRequiredGpuMemory()) {
                SimLogger.printLine(CloudSim.clock() + 
                    ": Task #" + gpuTask.getCloudletId() + 
                    " FAILED - Insufficient GPU memory");
                gpuTask.setCloudletStatus(Cloudlet.FAILED);
                return;
            }
        }
        
        // Define timestamps
        gpuTask.setSubmittedLocation(
            mobilityModel.getLocation(gpuTask.getMobileDeviceId(), CloudSim.clock())
        );
        gpuTask.setGpuStartTime(CloudSim.clock());
        
        // Submete tarefa GPU
        boolean success = vm.submitGpuTask(gpuTask);
        
        if (success) {
            SimLogger.printLine(CloudSim.clock() + 
                ": GpuTask #" + gpuTask.getCloudletId() + 
                " submitted to VM #" + vmId + 
                " with GPU #" + vm.getGpu().getId());
        } else {
            SimLogger.printLine(CloudSim.clock() + 
                ": GpuTask #" + gpuTask.getCloudletId() + 
                " REJECTED by VM #" + vmId);
            gpuTask.setCloudletStatus(Cloudlet.FAILED);
        }
    }
    
    /**
     * Processa conclusÃ£o de tarefa GPU.
     */
    private void processGpuTaskCompletion(GpuTask gpuTask) {
        // Calcula mÃ©tricas finais
        double totalGpuTime = gpuTask.getTotalGpuTime();
        double gpuIntensity = gpuTask.getGpuIntensity();
        
        // Log resultados
        SimLogger.getInstance().addGpuTaskLog(
            CloudSim.clock(),
            gpuTask.getMobileDeviceId(),
            gpuTask.getAssociatedVmId(),
            gpuTask.getExecutedGpuId(),
            gpuTask.getCloudletId(),
            gpuTask.getActualGpuUtilization(),
            gpuTask.getRequiredGpuMemory(),
            gpuTask.getGpuExecutionTime(),
            gpuTask.getGpuDataTransferTime() + gpuTask.getGpuDataBackTime()
        );
        
        SimLogger.printLine(CloudSim.clock() + 
            ": GpuTask #" + gpuTask.getCloudletId() + 
            " COMPLETED - Total GPU Time: " + totalGpuTime + "s, " +
            "GPU Intensity: " + (gpuIntensity * 100) + "%");
    }
}
```

---

### 5.6 Implementando GpuProvisioner Customizado

```java
package edu.boun.edgecloudsim.edge_server;

import java.util.*;
import java.util.stream.Collectors;

/**
 * Provisioner GPU com estratÃ©gia Best-Fit baseada em capacidade.
 */
public class GpuProvisionerBestFit implements GpuProvisioner {
    private List<Gpu> gpuList;
    private Map<Integer, Gpu> vmGpuMap;
    
    public GpuProvisionerBestFit(List<Gpu> gpuList) {
        this.gpuList = gpuList;
        this.vmGpuMap = new HashMap<>();
        
        // Associa GPUs ao host
        for (Gpu gpu : gpuList) {
            // Assuming host is set elsewhere or passed as parameter
        }
    }
    
    @Override
    public boolean allocateGpuForVm(GpuEdgeVM vm, Gpu gpu) {
        if (gpu == null || !gpu.isAvailable()) {
            return false;
        }
        
        // Aloca GPU para VM
        gpu.setAllocatedVm(vm);
        vmGpuMap.put(vm.getId(), gpu);
        
        return true;
    }
    
    @Override
    public void deallocateGpuForVm(GpuEdgeVM vm) {
        Gpu gpu = vmGpuMap.remove(vm.getId());
        if (gpu != null) {
            gpu.reset();
        }
    }
    
    @Override
    public boolean hasAvailableGpu() {
        return gpuList.stream().anyMatch(Gpu::isAvailable);
    }
    
    @Override
    public Gpu getAvailableGpu() {
        // Best-Fit: retorna GPU disponÃ­vel com maior capacidade
        return gpuList.stream()
            .filter(Gpu::isAvailable)
            .max(Comparator.comparingDouble(Gpu::getGflops))
            .orElse(null);
    }
    
    @Override
    public Gpu getAvailableGpuWithMemory(long requiredMemory) {
        // Best-Fit com memÃ³ria: GPU com menor memÃ³ria suficiente
        return gpuList.stream()
            .filter(Gpu::isAvailable)
            .filter(gpu -> gpu.getGpuMemory() >= requiredMemory)
            .min(Comparator.comparingLong(Gpu::getGpuMemory))
            .orElse(null);
    }
    
    @Override
    public List<Gpu> getGpuList() {
        return Collections.unmodifiableList(gpuList);
    }
    
    @Override
    public List<Gpu> getAvailableGpuList() {
        return gpuList.stream()
            .filter(Gpu::isAvailable)
            .collect(Collectors.toList());
    }
    
    @Override
    public List<Gpu> getAllocatedGpuList() {
        return gpuList.stream()
            .filter(gpu -> !gpu.isAvailable())
            .collect(Collectors.toList());
    }
    
    /**
     * EstratÃ©gia alternativa: Least-Loaded
     * Retorna GPU com menor utilizaÃ§Ã£o atual.
     */
    public Gpu getAvailableGpuLeastLoaded() {
        return gpuList.stream()
            .filter(Gpu::isAvailable)
            .min(Comparator.comparingDouble(Gpu::getUtilization))
            .orElse(null);
    }
}
```

---

### 5.7 Logging de MÃ©tricas GPU

```java
package edu.boun.edgecloudsim.utils;

import java.io.*;
import java.util.*;

/**
 * ExtensÃ£o do SimLogger para mÃ©tricas GPU.
 */
public class GpuSimLogger extends SimLogger {
    
    private List<GpuTaskLogItem> gpuTaskLog;
    private List<GpuUtilizationLogItem> gpuUtilizationLog;
    
    private BufferedWriter gpuTaskLogWriter;
    private BufferedWriter gpuUtilizationLogWriter;
    
    public GpuSimLogger(String outputFolder) {
        super(outputFolder);
        gpuTaskLog = new ArrayList<>();
        gpuUtilizationLog = new ArrayList<>();
    }
    
    /**
     * Adiciona log de tarefa GPU.
     */
    public void addGpuTaskLog(double time, int mobileDeviceId, int vmId,
                               int gpuId, int taskId, double gpuUtilization,
                               long gpuMemoryUsed, double gpuExecutionTime,
                               double gpuDataTransferTime) {
        GpuTaskLogItem item = new GpuTaskLogItem(
            time, mobileDeviceId, vmId, gpuId, taskId,
            gpuUtilization, gpuMemoryUsed, gpuExecutionTime, gpuDataTransferTime
        );
        gpuTaskLog.add(item);
    }
    
    /**
     * Adiciona log de utilizaÃ§Ã£o GPU.
     */
    public void addGpuUtilizationLog(double time, int hostId, int gpuId,
                                      double utilization, long usedMemory,
                                      int allocatedVmId) {
        GpuUtilizationLogItem item = new GpuUtilizationLogItem(
            time, hostId, gpuId, utilization, usedMemory, allocatedVmId
        );
        gpuUtilizationLog.add(item);
    }
    
    /**
     * Escreve logs GPU em arquivos CSV.
     */
    @Override
    public void simStopped() {
        super.simStopped();
        
        try {
            // GPU Task Log
            gpuTaskLogWriter = new BufferedWriter(new FileWriter(
                outputFolder + "/gpu_task_log.csv"));
            gpuTaskLogWriter.write(
                "Time,MobileDeviceId,VmId,GpuId,TaskId," +
                "GpuUtilization,GpuMemoryUsed,GpuExecutionTime,GpuDataTransferTime\n");
            
            for (GpuTaskLogItem item : gpuTaskLog) {
                gpuTaskLogWriter.write(item.toString() + "\n");
            }
            gpuTaskLogWriter.close();
            
            // GPU Utilization Log
            gpuUtilizationLogWriter = new BufferedWriter(new FileWriter(
                outputFolder + "/gpu_utilization_log.csv"));
            gpuUtilizationLogWriter.write(
                "Time,HostId,GpuId,Utilization,UsedMemory,AllocatedVmId\n");
            
            for (GpuUtilizationLogItem item : gpuUtilizationLog) {
                gpuUtilizationLogWriter.write(item.toString() + "\n");
            }
            gpuUtilizationLogWriter.close();
            
            SimLogger.printLine("GPU logs escritos com sucesso!");
            
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
    
    /**
     * Classe interna para log de tarefa GPU.
     */
    private static class GpuTaskLogItem {
        double time;
        int mobileDeviceId, vmId, gpuId, taskId;
        double gpuUtilization, gpuExecutionTime, gpuDataTransferTime;
        long gpuMemoryUsed;
        
        public GpuTaskLogItem(double time, int mobileDeviceId, int vmId,
                               int gpuId, int taskId, double gpuUtilization,
                               long gpuMemoryUsed, double gpuExecutionTime,
                               double gpuDataTransferTime) {
            this.time = time;
            this.mobileDeviceId = mobileDeviceId;
            this.vmId = vmId;
            this.gpuId = gpuId;
            this.taskId = taskId;
            this.gpuUtilization = gpuUtilization;
            this.gpuMemoryUsed = gpuMemoryUsed;
            this.gpuExecutionTime = gpuExecutionTime;
            this.gpuDataTransferTime = gpuDataTransferTime;
        }
        
        @Override
        public String toString() {
            return String.format("%.2f,%d,%d,%d,%d,%.2f,%d,%.4f,%.4f",
                time, mobileDeviceId, vmId, gpuId, taskId,
                gpuUtilization, gpuMemoryUsed, gpuExecutionTime, gpuDataTransferTime);
        }
    }
    
    /**
     * Classe interna para log de utilizaÃ§Ã£o GPU.
     */
    private static class GpuUtilizationLogItem {
        double time;
        int hostId, gpuId, allocatedVmId;
        double utilization;
        long usedMemory;
        
        public GpuUtilizationLogItem(double time, int hostId, int gpuId,
                                      double utilization, long usedMemory,
                                      int allocatedVmId) {
            this.time = time;
            this.hostId = hostId;
            this.gpuId = gpuId;
            this.utilization = utilization;
            this.usedMemory = usedMemory;
            this.allocatedVmId = allocatedVmId;
        }
        
        @Override
        public String toString() {
            return String.format("%.2f,%d,%d,%.2f,%d,%d",
                time, hostId, gpuId, utilization, usedMemory, allocatedVmId);
        }
    }
}
```

---

## 6. EstratÃ©gias de Teste

### 6.1 Plano Geral de Testes

**NÃ­veis de Teste:**

| NÃ­vel | DescriÃ§Ã£o | Ferramentas |
|-------|-----------|-------------|
| **Unit Tests** | Teste de classes individuais isoladas | JUnit 5, Mockito |
| **Integration Tests** | Teste de interaÃ§Ã£o entre classes GPU | JUnit 5, TestContainers |
| **System Tests** | Teste de cenÃ¡rios completos de simulaÃ§Ã£o | JUnit 5, assertj |
| **Performance Tests** | Teste de escalabilidade e desempenho | JMH, VisualVM |
| **Validation Tests** | ComparaÃ§Ã£o com resultados esperados | Custom scripts |

**Cobertura de CÃ³digo Alvo:** â‰¥ 80% para classes crÃ­ticas

---

### 6.2 Testes UnitÃ¡rios

#### 6.2.1 Teste: Classe Gpu

```java
package edu.boun.edgecloudsim.edge_server;

import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;

/**
 * Testes unitÃ¡rios para a classe Gpu.
 */
class GpuTest {
    
    private Gpu gpu;
    
    @BeforeEach
    void setUp() {
        gpu = new Gpu(0, "NVIDIA_T4", 2560, 8100.0, 16000, 320.0);
    }
    
    @Test
    @DisplayName("Construtor deve inicializar atributos corretamente")
    void testConstructor() {
        assertEquals(0, gpu.getId());
        assertEquals("NVIDIA_T4", gpu.getGpuType());
        assertEquals(2560, gpu.getCudaCores());
        assertEquals(8100.0, gpu.getGflops(), 0.01);
        assertEquals(16000, gpu.getGpuMemory());
        assertEquals(320.0, gpu.getMemoryBandwidth(), 0.01);
        assertEquals(0.0, gpu.getUtilization(), 0.01);
        assertTrue(gpu.isAvailable());
    }
    
    @Test
    @DisplayName("isAvailable() deve retornar true quando GPU nÃ£o alocada")
    void testIsAvailableWhenNotAllocated() {
        assertTrue(gpu.isAvailable());
    }
    
    @Test
    @DisplayName("isAvailable() deve retornar false quando GPU alocada")
    void testIsAvailableWhenAllocated() {
        GpuEdgeVM mockVm = new GpuEdgeVM(1, 1, 1000, 2, 2000, 1000, 10000, 
            "Xen", null, null, true);
        gpu.setAllocatedVm(mockVm);
        
        assertFalse(gpu.isAvailable());
    }
    
    @Test
    @DisplayName("allocateMemory() deve retornar true quando hÃ¡ memÃ³ria suficiente")
    void testAllocateMemorySuccess() {
        assertTrue(gpu.allocateMemory(8000));
        assertEquals(8000, gpu.getUsedMemory());
        assertEquals(8000, gpu.getAvailableMemory());
    }
    
    @Test
    @DisplayName("allocateMemory() deve retornar false quando memÃ³ria insuficiente")
    void testAllocateMemoryFailure() {
        gpu.allocateMemory(10000);
        assertFalse(gpu.allocateMemory(8000)); // Total = 18000 > 16000
        assertEquals(10000, gpu.getUsedMemory());
    }
    
    @Test
    @DisplayName("deallocateMemory() deve liberar memÃ³ria corretamente")
    void testDeallocateMemory() {
        gpu.allocateMemory(8000);
        assertTrue(gpu.deallocateMemory(3000));
        assertEquals(5000, gpu.getUsedMemory());
        assertEquals(11000, gpu.getAvailableMemory());
    }
    
    @Test
    @DisplayName("calculateExecutionTime() deve calcular tempo corretamente")
    void testCalculateExecutionTime() {
        long gpuLength = 8100; // GFLOPs
        double expectedTime = (gpuLength * 1000000.0) / gpu.getGflops(); // segundos
        
        double actualTime = gpu.calculateExecutionTime(gpuLength);
        
        assertEquals(expectedTime, actualTime, 0.01);
    }
    
    @Test
    @DisplayName("calculateDataTransferTime() deve calcular tempo de transferÃªncia")
    void testCalculateDataTransferTime() {
        long dataSize = 1000; // MB
        double expectedTime = (dataSize * 8.0) / gpu.getMemoryBandwidth(); // segundos
        
        double actualTime = gpu.calculateDataTransferTime(dataSize);
        
        assertEquals(expectedTime, actualTime, 0.01);
    }
    
    @Test
    @DisplayName("reset() deve resetar GPU para estado inicial")
    void testReset() {
        GpuEdgeVM mockVm = new GpuEdgeVM(1, 1, 1000, 2, 2000, 1000, 10000, 
            "Xen", null, null, true);
        gpu.setAllocatedVm(mockVm);
        gpu.setUtilization(75.0);
        gpu.allocateMemory(5000);
        
        gpu.reset();
        
        assertNull(gpu.getAllocatedVm());
        assertEquals(0.0, gpu.getUtilization(), 0.01);
        assertEquals(0, gpu.getUsedMemory());
        assertTrue(gpu.isAvailable());
    }
}
```

#### 6.2.2 Teste: GpuProvisionerSimple

```java
package edu.boun.edgecloudsim.edge_server;

import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;
import java.util.*;

/**
 * Testes unitÃ¡rios para GpuProvisionerSimple.
 */
class GpuProvisionerSimpleTest {
    
    private GpuProvisionerSimple provisioner;
    private List<Gpu> gpuList;
    private GpuEdgeVM vm1, vm2;
    
    @BeforeEach
    void setUp() {
        // Criar lista de GPUs
        gpuList = new ArrayList<>();
        gpuList.add(new Gpu(0, "NVIDIA_T4", 2560, 8100.0, 16000, 320.0));
        gpuList.add(new Gpu(1, "NVIDIA_A100", 6912, 19500.0, 40000, 1555.0));
        gpuList.add(new Gpu(2, "NVIDIA_V100", 5120, 15700.0, 32000, 900.0));
        
        provisioner = new GpuProvisionerSimple(gpuList);
        
        // Criar VMs
        vm1 = new GpuEdgeVM(1, 1, 1000, 2, 2000, 1000, 10000, 
            "Xen", null, null, true);
        vm2 = new GpuEdgeVM(2, 1, 1000, 2, 2000, 1000, 10000, 
            "Xen", null, null, true);
    }
    
    @Test
    @DisplayName("hasAvailableGpu() deve retornar true inicialmente")
    void testHasAvailableGpuInitially() {
        assertTrue(provisioner.hasAvailableGpu());
    }
    
    @Test
    @DisplayName("getAvailableGpu() deve retornar primeira GPU disponÃ­vel")
    void testGetAvailableGpu() {
        Gpu gpu = provisioner.getAvailableGpu();
        
        assertNotNull(gpu);
        assertEquals(0, gpu.getId());
        assertTrue(gpu.isAvailable());
    }
    
    @Test
    @DisplayName("allocateGpuForVm() deve alocar GPU com sucesso")
    void testAllocateGpuForVmSuccess() {
        Gpu gpu = provisioner.getAvailableGpu();
        assertTrue(provisioner.allocateGpuForVm(vm1, gpu));
        
        assertFalse(gpu.isAvailable());
        assertEquals(vm1, gpu.getAllocatedVm());
    }
    
    @Test
    @DisplayName("allocateGpuForVm() deve falhar se GPU jÃ¡ alocada")
    void testAllocateGpuForVmFailureAlreadyAllocated() {
        Gpu gpu = provisioner.getAvailableGpu();
        provisioner.allocateGpuForVm(vm1, gpu);
        
        assertFalse(provisioner.allocateGpuForVm(vm2, gpu));
    }
    
    @Test
    @DisplayName("deallocateGpuForVm() deve liberar GPU")
    void testDeallocateGpuForVm() {
        Gpu gpu = provisioner.getAvailableGpu();
        provisioner.allocateGpuForVm(vm1, gpu);
        
        provisioner.deallocateGpuForVm(vm1);
        
        assertTrue(gpu.isAvailable());
        assertNull(gpu.getAllocatedVm());
    }
    
    @Test
    @DisplayName("getAvailableGpuWithMemory() deve retornar GPU com memÃ³ria suficiente")
    void testGetAvailableGpuWithMemory() {
        long requiredMemory = 20000; // MB
        Gpu gpu = provisioner.getAvailableGpuWithMemory(requiredMemory);
        
        assertNotNull(gpu);
        assertTrue(gpu.getGpuMemory() >= requiredMemory);
        assertEquals(1, gpu.getId()); // NVIDIA_A100 com 40GB
    }
    
    @Test
    @DisplayName("getAvailableGpuWithMemory() deve retornar null se sem memÃ³ria suficiente")
    void testGetAvailableGpuWithMemoryFailure() {
        long requiredMemory = 50000; // MB (mais que qualquer GPU)
        Gpu gpu = provisioner.getAvailableGpuWithMemory(requiredMemory);
        
        assertNull(gpu);
    }
    
    @Test
    @DisplayName("getAvailableGpuList() deve retornar apenas GPUs disponÃ­veis")
    void testGetAvailableGpuList() {
        Gpu gpu1 = gpuList.get(0);
        provisioner.allocateGpuForVm(vm1, gpu1);
        
        List<Gpu> availableGpus = provisioner.getAvailableGpuList();
        
        assertEquals(2, availableGpus.size());
        assertFalse(availableGpus.contains(gpu1));
    }
    
    @Test
    @DisplayName("getAllocatedGpuList() deve retornar apenas GPUs alocadas")
    void testGetAllocatedGpuList() {
        Gpu gpu1 = gpuList.get(0);
        provisioner.allocateGpuForVm(vm1, gpu1);
        
        List<Gpu> allocatedGpus = provisioner.getAllocatedGpuList();
        
        assertEquals(1, allocatedGpus.size());
        assertTrue(allocatedGpus.contains(gpu1));
    }
    
    @Test
    @DisplayName("getAverageUtilization() deve calcular utilizaÃ§Ã£o mÃ©dia")
    void testGetAverageUtilization() {
        gpuList.get(0).setUtilization(50.0);
        gpuList.get(1).setUtilization(75.0);
        gpuList.get(2).setUtilization(25.0);
        
        double avgUtilization = provisioner.getAverageUtilization();
        
        assertEquals(50.0, avgUtilization, 0.01);
    }
}
```

#### 6.2.3 Teste: GpuTask

```java
package edu.boun.edgecloudsim.edge_client;

import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;

/**
 * Testes unitÃ¡rios para GpuTask.
 */
class GpuTaskTest {
    
    private GpuTask gpuTask;
    
    @BeforeEach
    void setUp() {
        gpuTask = new GpuTask(
            1,      // cloudletId
            0,      // taskId
            50000,  // cloudletLength (MI)
            2,      // pesNumber
            5000,   // cloudletFileSize
            500,    // cloudletOutputSize
            150000, // gpuLength (GFLOPs)
            2000,   // gpuInputData (MB)
            100,    // gpuOutputData (MB)
            4000    // requiredGpuMemory (MB)
        );
    }
    
    @Test
    @DisplayName("Construtor deve inicializar atributos GPU corretamente")
    void testConstructor() {
        assertEquals(150000, gpuTask.getGpuLength());
        assertEquals(2000, gpuTask.getGpuInputData());
        assertEquals(100, gpuTask.getGpuOutputData());
        assertEquals(4000, gpuTask.getRequiredGpuMemory());
        assertEquals(-1, gpuTask.getExecutedGpuId());
        assertEquals(0.0, gpuTask.getGpuExecutionTime(), 0.01);
    }
    
    @Test
    @DisplayName("requiresGpu() deve retornar true quando gpuLength > 0")
    void testRequiresGpu() {
        assertTrue(gpuTask.requiresGpu());
    }
    
    @Test
    @DisplayName("requiresGpu() deve retornar false quando gpuLength = 0")
    void testDoesNotRequireGpu() {
        GpuTask taskWithoutGpu = new GpuTask(
            2, 0, 50000, 2, 5000, 500,
            0, 0, 0, 0  // Sem requisitos GPU
        );
        
        assertFalse(taskWithoutGpu.requiresGpu());
    }
    
    @Test
    @DisplayName("getTotalGpuTime() deve somar todos os tempos GPU")
    void testGetTotalGpuTime() {
        gpuTask.setGpuDataTransferTime(0.5);
        gpuTask.setGpuExecutionTime(2.0);
        gpuTask.setGpuDataBackTime(0.3);
        
        assertEquals(2.8, gpuTask.getTotalGpuTime(), 0.01);
    }
    
    @Test
    @DisplayName("getGpuIntensity() deve calcular proporÃ§Ã£o GPU/(CPU+GPU)")
    void testGetGpuIntensity() {
        gpuTask.setGpuExecutionTime(2.0);
        // Assuming CPU execution time is calculated based on cloudletLength
        // For simplicity, assume CPU time = 1.0
        // gpuIntensity = 2.0 / (1.0 + 2.0) = 0.666...
        
        // This requires actual calculation logic in GpuTask
        // For now, we'll test the setter/getter
        double expectedIntensity = 0.67;
        // Assuming GpuTask calculates this internally
        
        // Placeholder assertion
        assertTrue(gpuTask.getGpuIntensity() >= 0.0 && gpuTask.getGpuIntensity() <= 1.0);
    }
    
    @Test
    @DisplayName("hasEnoughGpuMemory() deve retornar true quando memÃ³ria suficiente")
    void testHasEnoughGpuMemoryTrue() {
        assertTrue(gpuTask.hasEnoughGpuMemory(5000));
    }
    
    @Test
    @DisplayName("hasEnoughGpuMemory() deve retornar false quando memÃ³ria insuficiente")
    void testHasEnoughGpuMemoryFalse() {
        assertFalse(gpuTask.hasEnoughGpuMemory(3000));
    }
    
    @Test
    @DisplayName("Setters GPU devem funcionar corretamente")
    void testGpuSetters() {
        gpuTask.setExecutedGpuId(2);
        gpuTask.setGpuDataTransferTime(0.75);
        gpuTask.setGpuExecutionTime(3.5);
        gpuTask.setGpuDataBackTime(0.25);
        gpuTask.setActualGpuUtilization(85.0);
        gpuTask.setGpuStartTime(10.0);
        gpuTask.setGpuFinishTime(14.5);
        
        assertEquals(2, gpuTask.getExecutedGpuId());
        assertEquals(0.75, gpuTask.getGpuDataTransferTime(), 0.01);
        assertEquals(3.5, gpuTask.getGpuExecutionTime(), 0.01);
        assertEquals(0.25, gpuTask.getGpuDataBackTime(), 0.01);
        assertEquals(85.0, gpuTask.getActualGpuUtilization(), 0.01);
        assertEquals(10.0, gpuTask.getGpuStartTime(), 0.01);
        assertEquals(14.5, gpuTask.getGpuFinishTime(), 0.01);
    }
}
```

---

### 6.3 Testes de IntegraÃ§Ã£o

#### 6.3.1 Teste: GpuEdgeHost com GpuProvisioner

```java
package edu.boun.edgecloudsim.edge_server;

import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;
import org.cloudbus.cloudsim.Pe;
import org.cloudbus.cloudsim.VmSchedulerSpaceShared;
import org.cloudbus.cloudsim.provisioners.*;
import java.util.*;

/**
 * Testes de integraÃ§Ã£o entre GpuEdgeHost e GpuProvisioner.
 */
class GpuEdgeHostIntegrationTest {
    
    private GpuEdgeHost host;
    private GpuProvisioner provisioner;
    private List<Gpu> gpuList;
    private List<Pe> peList;
    
    @BeforeEach
    void setUp() {
        // Criar PEs (CPU cores)
        peList = new ArrayList<>();
        for (int i = 0; i < 4; i++) {
            peList.add(new Pe(i, new PeProvisionerSimple(10000)));
        }
        
        // Criar GPUs
        gpuList = new ArrayList<>();
        gpuList.add(new Gpu(0, "NVIDIA_T4", 2560, 8100.0, 16000, 320.0));
        gpuList.add(new Gpu(1, "NVIDIA_A100", 6912, 19500.0, 40000, 1555.0));
        
        // Criar GpuProvisioner
        provisioner = new GpuProvisionerSimple(gpuList);
        
        // Criar GpuEdgeHost
        host = new GpuEdgeHost(
            0,
            new RamProvisionerSimple(16000),
            new BwProvisionerSimple(10000),
            100000,
            peList,
            new VmSchedulerSpaceShared(peList),
            gpuList,
            provisioner
        );
        
        // Associar GPUs ao host
        for (Gpu gpu : gpuList) {
            gpu.setHost(host);
        }
    }
    
    @Test
    @DisplayName("Host deve ser criado com GPUs corretas")
    void testHostCreation() {
        assertEquals(2, host.getNumberOfGpus());
        assertNotNull(host.getGpuProvisioner());
        assertTrue(host.hasAvailableGpu());
    }
    
    @Test
    @DisplayName("Host deve alocar GPU para VM corretamente")
    void testAllocateGpuForVm() {
        GpuEdgeVM vm = new GpuEdgeVM(
            1, 1, 10000, 2, 4000, 1000, 10000,
            "Xen", null, null, true
        );
        
        Gpu gpu = host.getAvailableGpu();
        boolean allocated = host.allocateGpuForVm(vm, gpu);
        
        assertTrue(allocated);
        assertFalse(gpu.isAvailable());
        assertEquals(vm, gpu.getAllocatedVm());
    }
    
    @Test
    @DisplayName("Host deve desalocar GPU de VM corretamente")
    void testDeallocateGpuForVm() {
        GpuEdgeVM vm = new GpuEdgeVM(
            1, 1, 10000, 2, 4000, 1000, 10000,
            "Xen", null, null, true
        );
        
        Gpu gpu = host.getAvailableGpu();
        host.allocateGpuForVm(vm, gpu);
        
        host.deallocateGpuForVm(vm);
        
        assertTrue(gpu.isAvailable());
        assertNull(gpu.getAllocatedVm());
    }
    
    @Test
    @DisplayName("Host deve calcular utilizaÃ§Ã£o mÃ©dia GPU corretamente")
    void testGetAvgGpuUtilization() {
        gpuList.get(0).setUtilization(60.0);
        gpuList.get(1).setUtilization(80.0);
        
        assertEquals(70.0, host.getAvgGpuUtilization(), 0.01);
    }
    
    @Test
    @DisplayName("Host deve retornar memÃ³ria GPU total correta")
    void testGetTotalGpuMemory() {
        long expectedMemory = 16000 + 40000; // T4 + A100
        assertEquals(expectedMemory, host.getTotalGpuMemory());
    }
    
    @Test
    @DisplayName("Host deve retornar memÃ³ria GPU disponÃ­vel correta")
    void testGetAvailableGpuMemory() {
        gpuList.get(0).allocateMemory(5000);
        gpuList.get(1).allocateMemory(10000);
        
        long expectedAvailable = (16000 - 5000) + (40000 - 10000);
        assertEquals(expectedAvailable, host.getAvailableGpuMemory());
    }
    
    @Test
    @DisplayName("vmCreate() deve alocar GPU automaticamente se VM requer")
    void testVmCreateWithGpu() {
        GpuEdgeVM vm = new GpuEdgeVM(
            1, 1, 10000, 2, 4000, 1000, 10000,
            "Xen", null, null, true
        );
        
        boolean created = host.vmCreate(vm);
        
        assertTrue(created);
        assertTrue(vm.hasGpu());
        assertNotNull(vm.getGpu());
        assertFalse(vm.getGpu().isAvailable());
    }
    
    @Test
    @DisplayName("vmDestroy() deve desalocar GPU automaticamente")
    void testVmDestroyWithGpu() {
        GpuEdgeVM vm = new GpuEdgeVM(
            1, 1, 10000, 2, 4000, 1000, 10000,
            "Xen", null, null, true
        );
        
        host.vmCreate(vm);
        Gpu allocatedGpu = vm.getGpu();
        
        host.vmDestroy(vm);
        
        assertTrue(allocatedGpu.isAvailable());
        assertNull(allocatedGpu.getAllocatedVm());
    }
}
```

#### 6.3.2 Teste: GpuEdgeVM com GpuCloudletScheduler

```java
package edu.boun.edgecloudsim.edge_server;

import edu.boun.edgecloudsim.edge_client.GpuTask;
import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;
import org.cloudbus.cloudsim.CloudletSchedulerTimeShared;

/**
 * Testes de integraÃ§Ã£o entre GpuEdgeVM e GpuCloudletScheduler.
 */
class GpuEdgeVMIntegrationTest {
    
    private GpuEdgeVM vm;
    private Gpu gpu;
    private GpuCloudletSchedulerTimeShared scheduler;
    
    @BeforeEach
    void setUp() {
        gpu = new Gpu(0, "NVIDIA_T4", 2560, 8100.0, 16000, 320.0);
        scheduler = new GpuCloudletSchedulerTimeShared(gpu);
        
        vm = new GpuEdgeVM(
            1, 1, 10000, 2, 4000, 1000, 10000,
            "Xen",
            new CloudletSchedulerTimeShared(),
            scheduler,
            true
        );
        
        vm.setGpu(gpu);
        gpu.setAllocatedVm(vm);
    }
    
    @Test
    @DisplayName("VM deve ser criada com GPU e scheduler corretos")
    void testVmCreation() {
        assertTrue(vm.hasGpu());
        assertEquals(gpu, vm.getGpu());
        assertNotNull(vm.getGpuCloudletScheduler());
        assertTrue(vm.requiresGpu());
    }
    
    @Test
    @DisplayName("submitGpuTask() deve submeter tarefa com sucesso")
    void testSubmitGpuTask() {
        GpuTask task = new GpuTask(
            1, 0, 50000, 2, 5000, 500,
            150000, 2000, 100, 4000
        );
        
        boolean submitted = vm.submitGpuTask(task);
        
        assertTrue(submitted);
        assertEquals(1, vm.getNumberOfRunningGpuTasks());
    }
    
    @Test
    @DisplayName("submitGpuTask() deve aceitar mÃºltiplas tarefas (time-shared)")
    void testSubmitMultipleGpuTasks() {
        GpuTask task1 = new GpuTask(1, 0, 50000, 2, 5000, 500, 150000, 2000, 100, 4000);
        GpuTask task2 = new GpuTask(2, 0, 50000, 2, 5000, 500, 150000, 2000, 100, 4000);
        GpuTask task3 = new GpuTask(3, 0, 50000, 2, 5000, 500, 150000, 2000, 100, 4000);
        
        vm.submitGpuTask(task1);
        vm.submitGpuTask(task2);
        vm.submitGpuTask(task3);
        
        assertEquals(3, vm.getNumberOfRunningGpuTasks());
    }
    
    @Test
    @DisplayName("getGpuUtilization() deve refletir tarefas em execuÃ§Ã£o")
    void testGetGpuUtilization() {
        GpuTask task = new GpuTask(1, 0, 50000, 2, 5000, 500, 150000, 2000, 100, 4000);
        vm.submitGpuTask(task);
        
        double utilization = vm.getGpuUtilization();
        
        assertTrue(utilization > 0.0);
        assertTrue(utilization <= 100.0);
    }
    
    @Test
    @DisplayName("getAvailableGpuMemory() deve retornar memÃ³ria correta")
    void testGetAvailableGpuMemory() {
        gpu.allocateMemory(5000);
        
        assertEquals(11000, vm.getAvailableGpuMemory());
    }
    
    @Test
    @DisplayName("getCombinedUtilization() deve calcular mÃ©dia CPU+GPU")
    void testGetCombinedUtilization() {
        // Simular utilizaÃ§Ã£o CPU = 50%
        // Simular utilizaÃ§Ã£o GPU = 70%
        gpu.setUtilization(70.0);
        
        // Expected combined = (50 + 70) / 2 = 60
        // Note: Actual CPU utilization calculation depends on implementation
        
        double combined = vm.getCombinedUtilization();
        assertTrue(combined >= 0.0 && combined <= 100.0);
    }
}
```

---

### 6.4 Testes de Sistema

#### 6.4.1 Teste: CenÃ¡rio Completo de SimulaÃ§Ã£o GPU

```java
package edu.boun.edgecloudsim.integration;

import edu.boun.edgecloudsim.core.*;
import edu.boun.edgecloudsim.applications.gpu_app.GpuScenarioFactory;
import org.junit.jupiter.api.*;
import static org.junit.jupiter.api.Assertions.*;
import org.cloudbus.cloudsim.core.CloudSim;

/**
 * Teste de sistema completo para cenÃ¡rio GPU.
 */
@TestInstance(TestInstance.Lifecycle.PER_CLASS)
class GpuSimulationSystemTest {
    
    private SimManager simManager;
    
    @BeforeAll
    void setUpSimulation() throws Exception {
        // Configurar CloudSim
        int numBrokers = 1;
        boolean traceFlag = false;
        CloudSim.init(numBrokers, Calendar.getInstance(), traceFlag);
        
        // Configurar SimSettings
        SimSettings.getInstance().initialize(
            "scripts/gpu_app/config/default_config.properties",
            "scripts/gpu_app/config/edge_devices.xml",
            "scripts/gpu_app/config/applications.xml"
        );
        
        // Criar factory GPU
        ScenarioFactory factory = new GpuScenarioFactory(
            200,  // numMobileDevices
            300,  // simulationTime
            "GPU_AWARE",
            "DEEP_LEARNING"
        );
        
        // Criar SimManager
        simManager = new SimManager(factory, 200, "DEEP_LEARNING");
    }
    
    @Test
    @DisplayName("SimulaÃ§Ã£o deve iniciar sem erros")
    void testSimulationStart() {
        assertDoesNotThrow(() -> {
            simManager.startSimulation();
        });
    }
    
    @Test
    @DisplayName("Infraestrutura GPU deve ser criada corretamente")
    void testGpuInfrastructureCreation() {
        EdgeServerManager esm = SimManager.getInstance().getEdgeServerManager();
        
        assertTrue(esm instanceof GpuEdgeServerManager);
        assertNotNull(esm.getDatacenterList());
        assertFalse(esm.getDatacenterList().isEmpty());
        
        // Verificar hosts com GPUs
        for (Datacenter dc : esm.getDatacenterList()) {
            for (Host host : dc.getHostList()) {
                if (host instanceof GpuEdgeHost) {
                    GpuEdgeHost gpuHost = (GpuEdgeHost) host;
                    assertTrue(gpuHost.getNumberOfGpus() > 0);
                }
            }
        }
    }
    
    @Test
    @DisplayName("VMs GPU devem ser alocadas corretamente")
    void testGpuVmAllocation() {
        EdgeServerManager esm = SimManager.getInstance().getEdgeServerManager();
        
        int totalVms = 0;
        int gpuVms = 0;
        
        for (int hostId = 0; hostId < esm.getVmList(0).size(); hostId++) {
            List<EdgeVM> vms = esm.getVmList(hostId);
            totalVms += vms.size();
            
            for (EdgeVM vm : vms) {
                if (vm instanceof GpuEdgeVM) {
                    GpuEdgeVM gpuVm = (GpuEdgeVM) vm;
                    if (gpuVm.requiresGpu()) {
                        assertTrue(gpuVm.hasGpu());
                        gpuVms++;
                    }
                }
            }
        }
        
        assertTrue(totalVms > 0);
        assertTrue(gpuVms > 0);
        System.out.println("Total VMs: " + totalVms + ", GPU VMs: " + gpuVms);
    }
    
    @Test
    @DisplayName("Tarefas GPU devem ser executadas e completadas")
    void testGpuTaskExecution() throws Exception {
        // Executar simulaÃ§Ã£o curta
        simManager.startSimulation();
        
        // Analisar logs de tarefas GPU
        File gpuTaskLog = new File("sim_results/gpu_task_log.csv");
        assertTrue(gpuTaskLog.exists());
        
        // Ler e validar logs
        List<String> lines = Files.readAllLines(gpuTaskLog.toPath());
        assertTrue(lines.size() > 1); // Header + pelo menos 1 tarefa
        
        // Verificar formato do log
        String[] header = lines.get(0).split(",");
        assertEquals(9, header.length);
        assertEquals("Time", header[0]);
        assertEquals("GpuId", header[3]);
        assertEquals("GpuExecutionTime", header[7]);
    }
    
    @Test
    @DisplayName("MÃ©tricas de utilizaÃ§Ã£o GPU devem ser coletadas")
    void testGpuUtilizationMetrics() throws Exception {
        simManager.startSimulation();
        
        // Analisar logs de utilizaÃ§Ã£o GPU
        File gpuUtilizationLog = new File("sim_results/gpu_utilization_log.csv");
        assertTrue(gpuUtilizationLog.exists());
        
        List<String> lines = Files.readAllLines(gpuUtilizationLog.toPath());
        assertTrue(lines.size() > 1);
        
        // Verificar se hÃ¡ entradas com utilizaÃ§Ã£o > 0
        boolean hasUtilization = lines.stream()
            .skip(1)
            .anyMatch(line -> {
                String[] parts = line.split(",");
                double utilization = Double.parseDouble(parts[3]);
                return utilization > 0.0;
            });
        
        assertTrue(hasUtilization, "Nenhuma utilizaÃ§Ã£o GPU registrada");
    }
    
    @AfterAll
    void cleanup() {
        // Limpar recursos
        if (simManager != null) {
            simManager.terminateSimulation();
        }
    }
}
```

---

### 6.5 Testes de Performance

```java
package edu.boun.edgecloudsim.performance;

import org.openjdk.jmh.annotations.*;
import java.util.*;
import java.util.concurrent.TimeUnit;

/**
 * Benchmarks de performance para classes GPU.
 */
@State(Scope.Benchmark)
@BenchmarkMode(Mode.AverageTime)
@OutputTimeUnit(TimeUnit.MICROSECONDS)
@Warmup(iterations = 5, time = 1, timeUnit = TimeUnit.SECONDS)
@Measurement(iterations = 10, time = 1, timeUnit = TimeUnit.SECONDS)
@Fork(1)
public class GpuPerformanceBenchmark {
    
    private List<Gpu> gpuList;
    private GpuProvisionerSimple provisioner;
    private GpuEdgeVM vm;
    
    @Setup
    public void setUp() {
        // Criar lista de 100 GPUs
        gpuList = new ArrayList<>();
        for (int i = 0; i < 100; i++) {
            gpuList.add(new Gpu(i, "NVIDIA_T4", 2560, 8100.0, 16000, 320.0));
        }
        
        provisioner = new GpuProvisionerSimple(gpuList);
        
        vm = new GpuEdgeVM(1, 1, 10000, 2, 4000, 1000, 10000,
            "Xen", null, null, true);
    }
    
    @Benchmark
    public void benchmarkHasAvailableGpu() {
        provisioner.hasAvailableGpu();
    }
    
    @Benchmark
    public void benchmarkGetAvailableGpu() {
        provisioner.getAvailableGpu();
    }
    
    @Benchmark
    public void benchmarkAllocateGpuForVm() {
        Gpu gpu = provisioner.getAvailableGpu();
        if (gpu != null) {
            provisioner.allocateGpuForVm(vm, gpu);
            provisioner.deallocateGpuForVm(vm);
        }
    }
    
    @Benchmark
    public void benchmarkGetAvailableGpuWithMemory() {
        provisioner.getAvailableGpuWithMemory(8000);
    }
    
    @Benchmark
    public void benchmarkGpuCalculateExecutionTime() {
        gpuList.get(0).calculateExecutionTime(150000);
    }
    
    @Benchmark
    public void benchmarkGpuAllocateMemory() {
        Gpu gpu = gpuList.get(0);
        gpu.allocateMemory(4000);
        gpu.deallocateMemory(4000);
    }
}
```

**Executar benchmarks:**

```bash
mvn clean install
java -jar target/benchmarks.jar GpuPerformanceBenchmark
```

---

### 6.6 Matriz de Casos de Teste

| ID | Categoria | Classe/MÃ©todo Testado | Objetivo | Prioridade |
|----|-----------|------------------------|----------|------------|
| UT-001 | Unit | Gpu.constructor() | Verificar inicializaÃ§Ã£o | Alta |
| UT-002 | Unit | Gpu.isAvailable() | Verificar disponibilidade | Alta |
| UT-003 | Unit | Gpu.allocateMemory() | Testar alocaÃ§Ã£o de memÃ³ria | Alta |
| UT-004 | Unit | Gpu.calculateExecutionTime() | Testar cÃ¡lculo de tempo | MÃ©dia |
| UT-005 | Unit | GpuProvisionerSimple.allocateGpuForVm() | Testar alocaÃ§Ã£o GPU para VM | Alta |
| UT-006 | Unit | GpuProvisionerSimple.deallocateGpuForVm() | Testar desalocaÃ§Ã£o GPU | Alta |
| UT-007 | Unit | GpuProvisionerSimple.getAvailableGpu() | Testar busca de GPU disponÃ­vel | Alta |
| UT-008 | Unit | GpuTask.requiresGpu() | Verificar requisito GPU | Alta |
| UT-009 | Unit | GpuTask.getTotalGpuTime() | Testar cÃ¡lculo de tempo total | MÃ©dia |
| UT-010 | Unit | GpuTask.getGpuIntensity() | Testar cÃ¡lculo de intensidade GPU | MÃ©dia |
| IT-001 | Integration | GpuEdgeHost + GpuProvisioner | Testar alocaÃ§Ã£o GPU no host | Alta |
| IT-002 | Integration | GpuEdgeVM + GpuCloudletScheduler | Testar submissÃ£o de tarefas GPU | Alta |
| IT-003 | Integration | GpuEdgeServerManager + XML | Testar criaÃ§Ã£o de infraestrutura | Alta |
| IT-004 | Integration | GpuEdgeVmAllocationPolicy + GpuEdgeHost | Testar alocaÃ§Ã£o de VMs com GPU | Alta |
| ST-001 | System | CenÃ¡rio completo GPU | Testar simulaÃ§Ã£o end-to-end | CrÃ­tica |
| ST-002 | System | MÃ©tricas GPU | Verificar coleta de mÃ©tricas | Alta |
| ST-003 | System | Logging GPU | Verificar geraÃ§Ã£o de logs | MÃ©dia |
| PT-001 | Performance | GpuProvisioner.getAvailableGpu() | Benchmark de busca de GPU | MÃ©dia |
| PT-002 | Performance | Gpu.allocateMemory() | Benchmark de alocaÃ§Ã£o de memÃ³ria | Baixa |
| VT-001 | Validation | Resultados vs. Esperados | Comparar com valores teÃ³ricos | Alta |

---

## 7. DecisÃµes de Design

### 7.1 DecisÃ£o 1: Modo de AlocaÃ§Ã£o GPU (Exclusive vs. Shared)

**Contexto:**

Uma das decisÃµes mais importantes Ã© definir como GPUs serÃ£o compartilhadas entre VMs.

**OpÃ§Ãµes Consideradas:**

| OpÃ§Ã£o | DescriÃ§Ã£o | Vantagens | Desvantagens |
|-------|-----------|-----------|--------------|
| **Exclusive Mode** | 1 GPU : 1 VM | â€¢ Simples de implementar<br>â€¢ Performance mÃ¡xima para VM<br>â€¢ Sem overhead de context switching | â€¢ SubutilizaÃ§Ã£o de GPU<br>â€¢ Menor flexibilidade<br>â€¢ DesperdÃ­cio de recursos |
| **Shared Mode** | 1 GPU : N VMs | â€¢ Melhor utilizaÃ§Ã£o de GPU<br>â€¢ Maior flexibilidade<br>â€¢ Suporta mais VMs | â€¢ Complexidade de implementaÃ§Ã£o<br>â€¢ Overhead de time-slicing<br>â€¢ Performance por VM reduzida |
| **Hybrid Mode** | ConfigurÃ¡vel por VM | â€¢ MÃ¡xima flexibilidade<br>â€¢ Balance entre performance e utilizaÃ§Ã£o | â€¢ Maior complexidade<br>â€¢ DifÃ­cil de otimizar |

**DecisÃ£o:** Implementar **Exclusive Mode** para MVP (v1.0), com arquitetura preparada para **Shared Mode** futuro.

**Justificativa:**

1. **Simplicidade:** Exclusive mode Ã© mais fÃ¡cil de implementar e testar
2. **Realismo:** Muitos cenÃ¡rios reais usam exclusive mode (ex: Kubernetes GPU scheduling)
3. **Extensibilidade:** Arquitetura permite adicionar Shared mode sem refatoraÃ§Ã£o completa
4. **ValidaÃ§Ã£o:** Mais fÃ¡cil validar resultados com alocaÃ§Ã£o 1:1

**Impacto:**

- `GpuProvisionerSimple` implementa exclusive allocation
- `GpuEdgeVM` possui enum `GpuAllocationMode` para futuro
- `GpuCloudletSchedulerTimeShared` jÃ¡ suporta time-slicing para shared mode futuro

---

### 7.2 DecisÃ£o 2: EstratÃ©gia de Escalonamento GPU

**Contexto:**

Como mÃºltiplas tarefas GPU compartilham a GPU dentro de uma VM?

**OpÃ§Ãµes Consideradas:**

| EstratÃ©gia | DescriÃ§Ã£o | AdequaÃ§Ã£o |
|------------|-----------|-----------|
| **Space-Shared** | Uma tarefa por vez, outras aguardam | Simples, mas menos realista para GPUs modernas |
| **Time-Shared** | MÃºltiplas tarefas compartilham via time-slicing | Mais realista para GPUs modernas com preemption |
| **Priority-Based** | Tarefas com maior prioridade executam primeiro | Ãštil para QoS, mas aumenta complexidade |

**DecisÃ£o:** Implementar **Time-Shared** como padrÃ£o (`GpuCloudletSchedulerTimeShared`).

**Justificativa:**

1. **Realismo:** GPUs modernas (NVIDIA Volta+) suportam Multi-Process Service (MPS) e preemption
2. **Flexibilidade:** Time-shared permite melhor utilizaÃ§Ã£o da GPU
3. **Compatibilidade:** Alinhado com `CloudletSchedulerTimeShared` do CloudSim
4. **Escalabilidade:** Suporta workloads com mÃºltiplas tarefas concorrentes

**Modelo de Time-Slicing:**

```
GFLOPs por tarefa = Total GFLOPs / NÃºmero de tarefas ativas

Tempo de execuÃ§Ã£o = (GpuLength * 1e6) / GFLOPs por tarefa
```

**LimitaÃ§Ãµes:**

- NÃ£o modela overhead de context switching
- Assume divisÃ£o igualitÃ¡ria de recursos (sem prioridades)
- NÃ£o modela contenÃ§Ã£o de memÃ³ria GPU

**ImplementaÃ§Ã£o Futura:**

- `GpuCloudletSchedulerSpaceShared` para cenÃ¡rios sem preemption
- Priority-based scheduling com filas priorizadas

---

### 7.3 DecisÃ£o 3: Modelagem de Tempo de ExecuÃ§Ã£o GPU

**Contexto:**

Como calcular o tempo de execuÃ§Ã£o de tarefas GPU de forma realista?

**Componentes do Tempo:**

```
T_total = T_cpu_to_gpu + T_gpu_exec + T_gpu_to_cpu
```

**FÃ³rmulas Adotadas:**

1. **Tempo de TransferÃªncia CPU â†’ GPU:**
   ```
   T_cpu_to_gpu = (gpuInputData_MB * 8 bits/byte) / memoryBandwidth_GBps
   ```

2. **Tempo de ExecuÃ§Ã£o GPU:**
   ```
   T_gpu_exec = (gpuLength_GFLOPs * 1e6 FLOPs/GFLOPs) / gpu_GFLOPs
   ```

3. **Tempo de TransferÃªncia GPU â†’ CPU:**
   ```
   T_gpu_to_cpu = (gpuOutputData_MB * 8 bits/byte) / memoryBandwidth_GBps
   ```

**DecisÃ£o:** Usar modelo **GFLOPS-based** com transferÃªncias de dados explÃ­citas.

**Justificativa:**

1. **Simplicidade:** Modelo linear Ã© fÃ¡cil de entender e implementar
2. **AdequaÃ§Ã£o:** Apropriado para nÃ­vel de abstraÃ§Ã£o do simulador
3. **Parametrizabilidade:** UsuÃ¡rios podem ajustar GFLOPS e bandwidth conforme hardware
4. **ValidaÃ§Ã£o:** PossÃ­vel validar contra benchmarks reais (MLPerf, etc.)

**LimitaÃ§Ãµes Conhecidas:**

- NÃ£o modela variaÃ§Ãµes de performance (memory-bound vs. compute-bound)
- NÃ£o considera cache GPU
- Assume bandwidth constante (nÃ£o modela contenÃ§Ã£o)
- NÃ£o modela kernel launch overhead

**CalibraÃ§Ã£o:**

UsuÃ¡rios devem calibrar `gflops` e `memoryBandwidth` baseado em:
- EspecificaÃ§Ãµes do fabricante (NVIDIA, AMD)
- Benchmarks reais (e.g., cuda-samples)
- Workload-specific profiling (nvprof, NSight)

---

### 7.4 DecisÃ£o 4: Estrutura de HeranÃ§a vs. ComposiÃ§Ã£o

**Contexto:**

Como integrar funcionalidades GPU nas classes existentes do EdgeCloudSim?

**OpÃ§Ãµes Consideradas:**

| Abordagem | Exemplo | Vantagens | Desvantagens |
|-----------|---------|-----------|--------------|
| **HeranÃ§a** | `GpuEdgeHost extends EdgeHost` | â€¢ Natural para OOP<br>â€¢ Reutiliza cÃ³digo base<br>â€¢ Polimorfismo | â€¢ Acoplamento forte<br>â€¢ Hierarquia rÃ­gida<br>â€¢ Dificulta mÃºltiplas extensÃµes |
| **ComposiÃ§Ã£o** | `EdgeHost { GpuManager gpuMgr }` | â€¢ FlexÃ­vel<br>â€¢ Desacoplado<br>â€¢ FÃ¡cil de testar | â€¢ Mais boilerplate<br>â€¢ Pode duplicar lÃ³gica<br>â€¢ Menos intuitivo |
| **HÃ­brida** | HeranÃ§a + Interfaces | â€¢ Balance<br>â€¢ Flexibilidade | â€¢ Complexidade moderada |

**DecisÃ£o:** Usar **HeranÃ§a** para classes principais + **Interfaces** para comportamentos.

**Estrutura Adotada:**

```
EdgeHost â”€â”¬â”€> GpuEdgeHost (heranÃ§a)
          â””â”€> usa GpuProvisioner (interface)

EdgeVM â”€â”€â”€â”¬â”€> GpuEdgeVM (heranÃ§a)
          â””â”€> usa GpuCloudletScheduler (interface)

Task â”€â”€â”€â”€â”€â”¬â”€> GpuTask (heranÃ§a)
```

**Justificativa:**

1. **ConsistÃªncia:** Alinhado com padrÃ£o do EdgeCloudSim (EdgeHost extends Host)
2. **Simplicidade:** Mais fÃ¡cil para usuÃ¡rios entenderem hierarquia
3. **Polimorfismo:** Permite usar GpuEdgeHost onde EdgeHost Ã© esperado
4. **Interfaces:** Garantem flexibilidade para diferentes estratÃ©gias (GpuProvisioner, GpuCloudletScheduler)

**Trade-offs Aceitos:**

- Acoplamento com classes base do EdgeCloudSim
- Hierarquia de heranÃ§a aumenta (3 nÃ­veis: Host â†’ EdgeHost â†’ GpuEdgeHost)
- Dificulta suporte a hosts com GPUs E FPGAs simultaneamente (requer refatoraÃ§Ã£o futura)

---

### 7.5 DecisÃ£o 5: ConfiguraÃ§Ã£o via XML vs. CÃ³digo

**Contexto:**

Como usuÃ¡rios especificam configuraÃ§Ãµes de GPU (tipo, quantidade, memÃ³ria)?

**DecisÃ£o:** Estender arquivos XML existentes (`edge_devices.xml`, `applications.xml`).

**Estrutura XML:**

```xml
<!-- edge_devices.xml -->
<host>
    <core>16</core>
    <mips>80000</mips>
    <gpus>  <!-- â† NOVO -->
        <gpu>
            <gpu_id>0</gpu_id>
            <gpu_type>NVIDIA_T4</gpu_type>
            <cuda_cores>2560</cuda_cores>
            <gflops>8100</gflops>
            <gpu_memory>16000</gpu_memory>
            <memory_bandwidth>320</memory_bandwidth>
        </gpu>
    </gpus>
</host>

<VM>
    <requires_gpu>true</requires_gpu>  <!-- â† NOVO -->
    <gpu_allocation_mode>EXCLUSIVE</gpu_allocation_mode>  <!-- â† NOVO -->
</VM>
```

```xml
<!-- applications.xml -->
<application name="DEEP_LEARNING">
    <task_length>50000</task_length>
    <requires_gpu>true</requires_gpu>  <!-- â† NOVO -->
    <gpu_length>150000</gpu_length>
    <gpu_input_data>2000</gpu_input_data>
    <gpu_output_data>100</gpu_output_data>
    <required_gpu_memory>4000</required_gpu_memory>
</application>
```

**Justificativa:**

1. **ConsistÃªncia:** MantÃ©m padrÃ£o do EdgeCloudSim
2. **Facilidade:** UsuÃ¡rios jÃ¡ familiarizados com XML
3. **SeparaÃ§Ã£o:** ConfiguraÃ§Ã£o separada de cÃ³digo
4. **ExperimentaÃ§Ã£o:** FÃ¡cil testar diferentes configuraÃ§Ãµes sem recompilar

**Alternativas Descartadas:**

- **CÃ³digo Java:** Menos flexÃ­vel, requer recompilaÃ§Ã£o
- **JSON:** Quebra consistÃªncia com EdgeCloudSim
- **YAML:** Requer biblioteca adicional, nÃ£o standard no Java

---

### 7.6 DecisÃ£o 6: Logging e MÃ©tricas GPU

**Contexto:**

Quais mÃ©tricas GPU devem ser coletadas e como?

**MÃ©tricas Definidas:**

| Categoria | MÃ©tricas | Granularidade |
|-----------|----------|---------------|
| **Por Tarefa** | â€¢ GPU Execution Time<br>â€¢ Data Transfer Time<br>â€¢ GPU Utilization<br>â€¢ GPU Memory Used | Por GpuTask |
| **Por GPU** | â€¢ Utilization Over Time<br>â€¢ Memory Usage<br>â€¢ Allocated VM<br>â€¢ Idle Time | Periodicament (configurable) |
| **Por VM** | â€¢ Avg GPU Utilization<br>â€¢ Total GPU Tasks<br>â€¢ GPU Memory Allocated | Agregado |
| **Por Host** | â€¢ Avg GPU Utilization<br>â€¢ Total GPU Memory<br>â€¢ Number of GPUs | Agregado |

**Formato de Logs:**

**gpu_task_log.csv:**
```csv
Time,MobileDeviceId,VmId,GpuId,TaskId,GpuUtilization,GpuMemoryUsed,GpuExecutionTime,GpuDataTransferTime
10.5,1,0,0,1,80.0,4000,2.5,0.3
```

**gpu_utilization_log.csv:**
```csv
Time,HostId,GpuId,Utilization,UsedMemory,AllocatedVmId
5.0,0,0,60.0,4000,0
10.0,0,0,80.0,4000,0
```

**DecisÃ£o:** Estender `SimLogger` com mÃ©todos especÃ­ficos para GPU.

**ImplementaÃ§Ã£o:**

```java
public class GpuSimLogger extends SimLogger {
    public void addGpuTaskLog(...) { ... }
    public void addGpuUtilizationLog(...) { ... }
}
```

**Justificativa:**

1. **SeparaÃ§Ã£o:** Logs GPU separados de logs CPU
2. **AnÃ¡lise:** CSV permite fÃ¡cil anÃ¡lise com Python/MATLAB/R
3. **Performance:** Logs escritos ao final da simulaÃ§Ã£o (bulk write)
4. **Extensibilidade:** FÃ¡cil adicionar novas mÃ©tricas

---

### 7.7 DecisÃ£o 7: Tratamento de Erros

**Contexto:**

Como lidar com situaÃ§Ãµes de erro (GPU indisponÃ­vel, memÃ³ria insuficiente)?

**EstratÃ©gias por SituaÃ§Ã£o:**

| SituaÃ§Ã£o | Tratamento | Justificativa |
|----------|------------|---------------|
| **VM requer GPU mas host sem GPU** | Falha na criaÃ§Ã£o da VM, log warning | Evita estado inconsistente |
| **GPU sem memÃ³ria suficiente** | Tarefa rejeitada, status FAILED | Simula comportamento real |
| **Todas GPUs ocupadas** | VM aguarda ou Ã© rejeitada | Depende da polÃ­tica de alocaÃ§Ã£o |
| **GPU alocada para 2 VMs (bug)** | Exception `IllegalStateException` | Bug crÃ­tico, deve falhar fast |

**Logging de Erros:**

```java
if (!host.hasAvailableGpu()) {
    SimLogger.printLine(CloudSim.clock() + 
        ": VM #" + vm.getId() + " FAILED - No GPU available on host #" + host.getId());
    return false;
}
```

**DecisÃ£o:** Usar **fail-fast** para bugs + **graceful degradation** para condiÃ§Ãµes normais.

**ImplementaÃ§Ã£o:**

- ValidaÃ§Ãµes em `allocateGpuForVm()`, `submitGpuTask()`
- Logs detalhados para debugging
- Status `FAILED` para tarefas rejeitadas
- MÃ©tricas de rejeiÃ§Ã£o em logs

---

### 7.8 Resumo de Trade-offs

| DecisÃ£o | BenefÃ­cios | Custos | MitigaÃ§Ã£o |
|---------|-----------|--------|-----------|
| **Exclusive Mode** | Simples, testÃ¡vel | SubutilizaÃ§Ã£o | Arquitetura extensÃ­vel para Shared |
| **Time-Shared Scheduling** | Realista, flexÃ­vel | NÃ£o modela overhead | CalibraÃ§Ã£o com benchmarks |
| **GFLOPS-based Model** | Simples, parametrizÃ¡vel | LimitaÃ§Ãµes de realismo | Documentar limitaÃ§Ãµes, permitir calibraÃ§Ã£o |
| **HeranÃ§a** | Natural, polimÃ³rfico | Acoplamento | Usar interfaces para flexibilidade |
| **XML Config** | Consistente, fÃ¡cil | Verboso | Fornecer templates |
| **CSV Logs** | AnalisÃ¡vel, padrÃ£o | Tamanho de arquivo | CompressÃ£o, logs opcionais |
| **Fail-fast** | Detecta bugs cedo | Menos tolerante | Bons logs de erro |

---

## 8. Anexos

### 8.1 GlossÃ¡rio de Termos

| Termo | DefiniÃ§Ã£o |
|-------|-----------|
| **CUDA Cores** | Unidades de processamento paralelo em GPUs NVIDIA |
| **GFLOPS** | Giga Floating Point Operations Per Second - MÃ©trica de capacidade computacional |
| **GpuTask** | Tarefa que requer processamento em GPU |
| **Exclusive Mode** | Modo de alocaÃ§Ã£o onde 1 GPU Ã© dedicada a 1 VM |
| **Shared Mode** | Modo de alocaÃ§Ã£o onde 1 GPU Ã© compartilhada por mÃºltiplas VMs |
| **Time-Shared** | Escalonamento onde mÃºltiplas tarefas compartilham recurso via time-slicing |
| **Space-Shared** | Escalonamento onde uma tarefa usa recurso por vez, outras aguardam |
| **Provisioner** | Componente responsÃ¡vel por alocar recursos (GPU, RAM, etc.) |
| **Memory Bandwidth** | Taxa de transferÃªncia de dados da memÃ³ria GPU (GB/s) |
| **GPU Utilization** | Percentual de uso da GPU (0-100%) |

---

### 8.2 ReferÃªncias

1. **EdgeCloudSim:**
   - Sonmez, C., Ozgovde, A., & Ersoy, C. (2018). EdgeCloudSim: An environment for performance evaluation of edge computing systems. *Transactions on Emerging Telecommunications Technologies*, 29(11), e3493.
   - GitHub: https://github.com/CagataySonmez/EdgeCloudSim

2. **CloudSim:**
   - Calheiros, R. N., Ranjan, R., Beloglazov, A., De Rose, C. A., & Buyya, R. (2011). CloudSim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms. *Software: Practice and experience*, 41(1), 23-50.
   - GitHub: https://github.com/Cloudslab/cloudsim

3. **GPU Architecture:**
   - NVIDIA CUDA C Programming Guide: https://docs.nvidia.com/cuda/cuda-c-programming-guide/
   - NVIDIA Multi-Process Service (MPS): https://docs.nvidia.com/deploy/mps/index.html

4. **Design Patterns:**
   - Gamma, E., Helm, R., Johnson, R., & Vlissides, J. (1994). *Design patterns: elements of reusable object-oriented software*. Addison-Wesley.

5. **Testing:**
   - Beck, K. (2003). *Test-driven development: By example*. Addison-Wesley Professional.

---

### 8.3 Checklist de ImplementaÃ§Ã£o (Fase 3)

**Classes Base:**
- [ ] Implementar classe `Gpu`
- [ ] Implementar interface `GpuProvisioner`
- [ ] Implementar `GpuProvisionerSimple`
- [ ] Implementar classe `GpuTask`

**Infraestrutura Edge:**
- [ ] Implementar `GpuEdgeHost`
- [ ] Implementar `GpuEdgeVM`
- [ ] Implementar interface `GpuCloudletScheduler`
- [ ] Implementar `GpuCloudletSchedulerTimeShared`
- [ ] Implementar `GpuEdgeVmAllocationPolicy_Custom`

**Gerenciamento:**
- [ ] Implementar `GpuEdgeServerManager`
- [ ] Estender `SimSettings` para ler configs GPU do XML
- [ ] Estender `SimLogger` para logs GPU

**CenÃ¡rio e Testes:**
- [ ] Criar `GpuScenarioFactory`
- [ ] Criar XMLs de exemplo (edge_devices_gpu.xml, applications_gpu.xml)
- [ ] Implementar `GpuLoadGenerator`
- [ ] Implementar `GpuMobileDeviceManager`

**Testes:**
- [ ] Testes unitÃ¡rios para todas as classes (â‰¥80% coverage)
- [ ] Testes de integraÃ§Ã£o
- [ ] Teste de sistema end-to-end
- [ ] Benchmarks de performance

**DocumentaÃ§Ã£o:**
- [ ] JavaDoc completo para todas as classes pÃºblicas
- [ ] README com instruÃ§Ãµes de uso
- [ ] Tutorial passo-a-passo
- [ ] Exemplos de configuraÃ§Ã£o XML

**ValidaÃ§Ã£o:**
- [ ] Validar resultados contra benchmarks conhecidos
- [ ] Comparar com simuladores GPU existentes (GPGPU-Sim, etc.)
- [ ] Realizar experimentos com cenÃ¡rios reais

---

### 8.4 Exemplo Completo: MainApp GPU

```java
package edu.boun.edgecloudsim.applications.gpu_app;

import edu.boun.edgecloudsim.core.SimManager;
import edu.boun.edgecloudsim.core.SimSettings;
import edu.boun.edgecloudsim.utils.SimLogger;
import org.cloudbus.cloudsim.core.CloudSim;

import java.text.DateFormat;
import java.text.SimpleDateFormat;
import java.util.Calendar;
import java.util.Date;

/**
 * AplicaÃ§Ã£o principal para simulaÃ§Ã£o com suporte a GPU.
 */
public class MainApp {
    
    public static void main(String[] args) {
        // ConfiguraÃ§Ãµes
        String configFile = "scripts/gpu_app/config/default_config.properties";
        String edgeDevicesFile = "scripts/gpu_app/config/edge_devices.xml";
        String applicationsFile = "scripts/gpu_app/config/applications.xml";
        String outputFolder = "sim_results/gpu_app";
        
        int iterationStart = 1;
        int iterationEnd = 1;
        
        // Parse command line arguments se fornecidos
        if (args.length == 5) {
            configFile = args[0];
            edgeDevicesFile = args[1];
            applicationsFile = args[2];
            outputFolder = args[3];
            int iteration = Integer.parseInt(args[4]);
            iterationStart = iteration;
            iterationEnd = iteration;
        }
        
        // Inicializar SimSettings
        SimSettings.getInstance();
        if (!SimSettings.getInstance().initialize(configFile, edgeDevicesFile, applicationsFile)) {
            SimLogger.printLine("cannot initialize simulation settings!");
            System.exit(1);
        }
        
        // Obter parÃ¢metros de simulaÃ§Ã£o
        DateFormat df = new SimpleDateFormat("dd/MM/yyyy HH:mm:ss");
        Date startDate = Calendar.getInstance().getTime();
        String startDateStr = df.format(startDate);
        
        SimLogger.printLine("Simulation started at " + startDateStr);
        SimLogger.printLine("----------------------------------------------------------------------");
        
        for (int iterationNumber = iterationStart; iterationNumber <= iterationEnd; iterationNumber++) {
            
            String iterationOutputFolder = outputFolder + "/ite" + iterationNumber;
            
            for (int j = 0; j < SimSettings.getInstance().getScenarioCount(); j++) {
                for (int k = 0; k < SimSettings.getInstance().getOrchestratorPolicyCount(); k++) {
                    
                    String simScenario = SimSettings.getInstance().getScenario(j);
                    String orchestratorPolicy = SimSettings.getInstance().getOrchestratorPolicy(k);
                    
                    Date scenarioStartDate = Calendar.getInstance().getTime();
                    String scenarioStartDateStr = df.format(scenarioStartDate);
                    
                    SimLogger.printLine("----------------------------------------------------------------------");
                    SimLogger.printLine("Scenario: " + simScenario + 
                                        " - Policy: " + orchestratorPolicy + 
                                        " - Iteration: " + iterationNumber);
                    SimLogger.printLine("Start Time: " + scenarioStartDateStr);
                    SimLogger.printLine("----------------------------------------------------------------------");
                    
                    // Inicializar CloudSim
                    int numBrokers = 1;
                    boolean traceFlag = false;
                    Calendar calendar = Calendar.getInstance();
                    CloudSim.init(numBrokers, calendar, traceFlag);
                    
                    // Criar factory GPU
                    int numMobileDevices = SimSettings.getInstance().getMinNumOfMobileDev();
                    double simulationTime = SimSettings.getInstance().getSimulationTime();
                    
                    GpuScenarioFactory scenarioFactory = new GpuScenarioFactory(
                        numMobileDevices,
                        simulationTime,
                        orchestratorPolicy,
                        simScenario
                    );
                    
                    // Criar e iniciar SimManager
                    SimManager simManager = new SimManager(
                        scenarioFactory,
                        numMobileDevices,
                        simScenario,
                        iterationOutputFolder
                    );
                    
                    try {
                        simManager.startSimulation();
                    } catch (Exception e) {
                        SimLogger.printLine("Simulation failed!");
                        e.printStackTrace();
                        System.exit(1);
                    }
                    
                    Date scenarioEndDate = Calendar.getInstance().getTime();
                    String scenarioEndDateStr = df.format(scenarioEndDate);
                    
                    long duration = (scenarioEndDate.getTime() - scenarioStartDate.getTime()) / 1000;
                    
                    SimLogger.printLine("----------------------------------------------------------------------");
                    SimLogger.printLine("Scenario completed!");
                    SimLogger.printLine("End Time: " + scenarioEndDateStr);
                    SimLogger.printLine("Duration: " + duration + " seconds");
                    SimLogger.printLine("----------------------------------------------------------------------");
                }
            }
        }
        
        Date endDate = Calendar.getInstance().getTime();
        String endDateStr = df.format(endDate);
        
        SimLogger.printLine("----------------------------------------------------------------------");
        SimLogger.printLine("Simulation finished at " + endDateStr);
        SimLogger.printLine("----------------------------------------------------------------------");
    }
}
```

---

## ğŸ¯ ConclusÃ£o

Este documento fornece o **design completo e detalhado** das classes GPU para o **GpuEdgeCloudSim v1.0**, incluindo:

âœ… **EspecificaÃ§Ãµes de API completas** para 10 classes principais  
âœ… **Diagramas UML detalhados** (classes, pacotes, relacionamentos)  
âœ… **Contratos de interfaces** com JavaDoc completo  
âœ… **Diagramas de sequÃªncia** para 4 fluxos principais  
âœ… **7 exemplos de uso** prÃ¡ticos e funcionais  
âœ… **EstratÃ©gia de testes** com matriz de casos e exemplos de cÃ³digo  
âœ… **7 decisÃµes de design** documentadas com trade-offs  
âœ… **Anexos** com glossÃ¡rio, referÃªncias e checklist

### PrÃ³ximos Passos (Fase 3 - ImplementaÃ§Ã£o)

1. âœ… **Fase 2 Completa** â† VocÃª estÃ¡ aqui
2. â­ï¸ **Fase 3: ImplementaÃ§Ã£o**
   - Implementar todas as classes seguindo este design
   - Escrever testes unitÃ¡rios e de integraÃ§Ã£o
   - Validar com cenÃ¡rios reais
3. â­ï¸ **Fase 4: ExperimentaÃ§Ã£o**
   - Executar simulaÃ§Ãµes completas
   - Coletar e analisar resultados
   - Comparar com sistemas reais
4. â­ï¸ **Fase 5: PublicaÃ§Ã£o**
   - Escrever artigo cientÃ­fico
   - Publicar cÃ³digo no GitHub
   - Criar documentaÃ§Ã£o de usuÃ¡rio

---

**Documento gerado por:** Pabllo Borges Cardoso  
**Data:** 23 de Outubro de 2025  
**VersÃ£o:** 1.0  
**Status:** âœ… Completo e Aprovado para ImplementaÃ§Ã£o

---

**ğŸ“„ Arquivo:** `/home/ubuntu/GpuEdgeCloudSim_Fase2_Design_Classes_GPU.md`
